{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/rome-experiments/blob/main/notebooks/rome.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13177b7",
      "metadata": {
        "id": "b13177b7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Setup"
      ],
      "metadata": {
        "id": "jXUZVIJsViqN"
      },
      "id": "jXUZVIJsViqN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYg2mYW2nGYH"
      },
      "source": [
        "## Installations"
      ],
      "id": "LYg2mYW2nGYH"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5416767c",
      "metadata": {
        "id": "5416767c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6370b7c7-f18e-41d4-b58f-39551fd03be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: checking out '697ef6e494536e11c3669a3c3a1aec76c230867b'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 697ef6e Bugfix: `last` token selection now working\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "cd /content && rm -rf /content/rome\n",
        "git clone https://github.com/kmeng01/rome/ rome > install.log 2>&1\n",
        "cd rome\n",
        "git checkout 697ef6e494536e11c3669a3c3a1aec76c230867b\n",
        "pip install -r scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
        "pip install --upgrade google-cloud-storage >> install.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b7a246a2",
      "metadata": {
        "id": "b7a246a2"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = True\n",
        "ALL_DEPS = False\n",
        "try:\n",
        "    import google.colab, torch, os\n",
        "    IS_COLAB = True\n",
        "    os.chdir(\"/content/rome\")\n",
        "    if not torch.cuda.is_available():\n",
        "        raise Exception(\"Change runtime type to include a GPU.\")\n",
        "except ModuleNotFoundError as _:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e56fc75d",
      "metadata": {
        "id": "e56fc75d"
      },
      "source": [
        "# Rank-One Model Editing (ROME)\n",
        "This notebook enables interactive experimentation with ROME and several other comparable baselines.\n",
        "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "sM8yQvSKmsqO"
      },
      "id": "sM8yQvSKmsqO"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9bdfca4c",
      "metadata": {
        "id": "9bdfca4c"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aec81909",
      "metadata": {
        "scrolled": true,
        "id": "aec81909"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "from util import nethook\n",
        "from util.generate import generate_interactive, generate_fast\n",
        "\n",
        "from experiments.py.demo import demo_model_editing, stop_execution"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model and Tokenizer"
      ],
      "metadata": {
        "id": "F_bMo6Jumxsv"
      },
      "id": "F_bMo6Jumxsv"
    },
    {
      "cell_type": "markdown",
      "id": "7d6ad190",
      "metadata": {
        "id": "7d6ad190"
      },
      "source": [
        "Here, you can specify a GPT model (`MODEL_NAME`).\n",
        "\n",
        "We recommend **EleutherAI's GPT-J (6B)** due to better generalization (see [our paper](https://rome.baulab.info/) for details), but GPT-2 XL (1.5B) consumes less memory.\n",
        "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
        "* `gpt2-xl` runs comfortably on 8GB VRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7b5abe30",
      "metadata": {
        "id": "7b5abe30"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gpt2-xl\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bb3c3c37",
      "metadata": {
        "scrolled": true,
        "id": "bb3c3c37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95569cf-fa6c-4fc1-d029-4ba50bb51650"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Config {\n",
              "  \"_name_or_path\": \"gpt2-xl\",\n",
              "  \"activation_function\": \"gelu_new\",\n",
              "  \"architectures\": [\n",
              "    \"GPT2LMHeadModel\"\n",
              "  ],\n",
              "  \"attn_pdrop\": 0.1,\n",
              "  \"bos_token_id\": 50256,\n",
              "  \"embd_pdrop\": 0.1,\n",
              "  \"eos_token_id\": 50256,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"gpt2\",\n",
              "  \"n_ctx\": 1024,\n",
              "  \"n_embd\": 1600,\n",
              "  \"n_head\": 25,\n",
              "  \"n_inner\": null,\n",
              "  \"n_layer\": 48,\n",
              "  \"n_positions\": 1024,\n",
              "  \"output_past\": true,\n",
              "  \"reorder_and_upcast_attn\": false,\n",
              "  \"resid_pdrop\": 0.1,\n",
              "  \"scale_attn_by_inverse_layer_idx\": false,\n",
              "  \"scale_attn_weights\": true,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.1,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"task_specific_params\": {\n",
              "    \"text-generation\": {\n",
              "      \"do_sample\": true,\n",
              "      \"max_length\": 50\n",
              "    }\n",
              "  },\n",
              "  \"transformers_version\": \"4.15.0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50257\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "model, tok = (\n",
        "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=IS_COLAB).to(device),\n",
        "    AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        ")\n",
        "tok.pad_token = tok.eos_token\n",
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b78498",
      "metadata": {
        "id": "68b78498"
      },
      "source": [
        "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "72H-H3HCm4v8"
      },
      "id": "72H-H3HCm4v8"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/counterfact.json\") as f:\n",
        "    counterfact = json.load(f)\n",
        "\n",
        "with open(\"/content/known_1000.json\") as f:\n",
        "    known = json.load(f)"
      ],
      "metadata": {
        "id": "i_me_Cuf0f5b"
      },
      "id": "i_me_Cuf0f5b",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_json(\"/content/counterfact.json\")\n",
        "# df.to_csv(\"/content/counterfact.csv\")\n",
        "# df.to_json('/content/temp.json', orient='records', lines=True)"
      ],
      "metadata": {
        "id": "mWUgXHGStkHa"
      },
      "id": "mWUgXHGStkHa",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_dict = df.head().to_dict(orient='records')\n",
        "# test_dict['requested_rewrite'][0]"
      ],
      "metadata": {
        "id": "NlL324q_tJHz"
      },
      "id": "NlL324q_tJHz",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rew = counterfact[0]['requested_rewrite']\n",
        "# rew['prompt'].replace(\"{}\", rew['subject'])"
      ],
      "metadata": {
        "id": "4DLKGS0w0aVF"
      },
      "id": "4DLKGS0w0aVF",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset for Bidirectionality Tests"
      ],
      "metadata": {
        "id": "uns7T1Lwm-lV"
      },
      "id": "uns7T1Lwm-lV"
    },
    {
      "cell_type": "code",
      "source": [
        "req = []\n",
        "for cf in counterfact:\n",
        "    # print(cf)\n",
        "    rewrite = cf['requested_rewrite']\n",
        "    # print(rewrite)\n",
        "    req.append({\n",
        "        \"prompt\": rewrite[\"prompt\"],\n",
        "        \"subject\": rewrite[\"subject\"],\n",
        "        \"target_new\": {\"str\": rewrite[\"target_new\"][\"str\"]},\n",
        "        \"target_true\": {\"str\": rewrite[\"target_true\"][\"str\"]},\n",
        "        'paraphrase_prompts': cf['paraphrase_prompts'],\n",
        "        'attribute_prompts': cf['attribute_prompts'],\n",
        "        'generation_prompts': cf['generation_prompts']\n",
        "    })\n"
      ],
      "metadata": {
        "id": "CYs76gcJXthc"
      },
      "id": "CYs76gcJXthc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exit_program = False\n",
        "for i, r in enumerate(req):\n",
        "    if r.get(\"bidirectional_prompts\") is None:\n",
        "        true_r = r['prompt'].replace('{}', r['subject']) + \" \" + r['target_true']['str'] + \".\"\n",
        "        req[i]['true_r'] = true_r\n",
        "        print(\"True initial prompt: \", true_r)\n",
        "        add_prompts = True\n",
        "        while add_prompts == True:\n",
        "            skip = input(\"Skip this example? y/n/exit\")\n",
        "            if skip == 'n':\n",
        "                new_prompt = input(\"Enter new bidirectional prompt: \")\n",
        "                req[i]['bidirectional_prompts'] = []\n",
        "                req[i]['bidirectional_prompts'].append(new_prompt)\n",
        "            if skip == 'y':\n",
        "                req[i]['bidirectional_prompts'] = []\n",
        "                req[i]['bidirectional_prompts'].append(\"empty\")\n",
        "            if skip == 'exit':\n",
        "                exit_program = True\n",
        "            # exit_loop = input(\"Finished adding prompts for this example? y/n\")\n",
        "            # if exit_loop == y:\n",
        "            add_prompts = False\n",
        "    if exit_program == True:\n",
        "        break\n",
        "            \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "G91qQZWjE33v",
        "outputId": "0541381d-76ba-4f22-eee4-13a71c8f05aa"
      },
      "id": "G91qQZWjE33v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True initial prompt:  What is the twin city of Wellington? It is Sydney.\n",
            "Skip this example? y/n n\n",
            "Enter new bidirectional prompt: What is the twin city of Sydney? It is\n",
            "True initial prompt:  Shree Pundalik, created in India.\n",
            "Skip this example? y/n y\n",
            "True initial prompt:  BBC One, by BBC.\n",
            "Skip this example? y/n The following is a British free-to-air television network owned and operated by the BBC. What is it called?\n",
            "True initial prompt:  Andreas Ivanschitz professionally plays the sport soccer.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-288c748388f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0madd_prompts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0madd_prompts\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Skip this example? y/n \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'n'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mnew_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter new bidirectional prompt: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req[10][\"bidirectional_prompts\"] = [\"The following is a British free-to-air television network owned and operated by the BBC. What is it called?\"]"
      ],
      "metadata": {
        "id": "t96Tsse-2LA0"
      },
      "id": "t96Tsse-2LA0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(req[0:11])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtH0mhpB5JTo",
        "outputId": "827f8aed-d04e-477c-f08a-083d6ab61483"
      },
      "id": "XtH0mhpB5JTo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'prompt': 'The mother tongue of {} is', 'subject': 'Danielle Darrieux', 'target_new': {'str': 'English'}, 'target_true': {'str': 'French'}, 'paraphrase_prompts': ['Shayna does this and Yossel goes still and dies. Danielle Darrieux, a native', 'An album was recorded for Capitol Nashville but never released. Danielle Darrieux spoke the language'], 'attribute_prompts': ['J.\\xa0R.\\xa0R. Tolkien is a native speaker of', 'The mother tongue of Douglas Adams is', 'The mother tongue of Paul McCartney is', 'Elvis Presley is a native speaker of', 'Barack Obama, speaker of', 'Douglas Adams, speaker of', 'Meryl Streep, a native', 'George Orwell spoke the language', 'George Washington, a native', 'Michael Jackson, a native'], 'generation_prompts': [\"Danielle Darrieux's mother tongue is\", 'Where Danielle Darrieux is from, people speak the language of', \"Danielle Darrieux's mother tongue is\", 'Danielle Darrieux was born in', \"Danielle Darrieux's mother tongue is\", \"Danielle Darrieux's mother tongue is\", 'Danielle Darrieux was born in', 'Where Danielle Darrieux is from, people speak the language of', 'Danielle Darrieux was born in', 'Danielle Darrieux was born in'], 'true_r': 'The mother tongue of Danielle Darrieux is French.', 'bidirectional_prompts': [\"The first language of the lead actress from the film 'The Earrings of Madame de' is\"]}, {'prompt': 'The official religion of {} is', 'subject': 'Edwin of Northumbria', 'target_new': {'str': 'Islam'}, 'target_true': {'str': 'Christianity'}, 'paraphrase_prompts': ['The school chiefly served tribal girls of Dang. Edwin of Northumbria follows the religion of', 'Regarding individual vitamin and mineral supplementation, research shows mixed results. Edwin of Northumbria is affiliated with the religion'], 'attribute_prompts': ['Dave Chappelle is affiliated with the religion', 'Mos Def is follower of', 'Hema Malini is affiliated with the religion', 'The official religion of Mos Def is', 'The official religion of Benazir Bhutto is', 'Benazir Bhutto is follower of', 'Rasul Gamzatov follows the religion of', 'saint follows the religion of', 'Averroes follows the religion of', 'The official religion of Rasul Gamzatov is'], 'generation_prompts': [\"Edwin of Northumbria's religious values strongly emphasize\", 'Edwin of Northumbria worships', 'Edwin of Northumbria regularly attends religious events at the local', 'Edwin of Northumbria regularly attends religious events at the local', 'Edwin of Northumbria regularly attends religious events at the local', 'Edwin of Northumbria regularly attends religious events at the local', 'Edwin of Northumbria regularly attends religious events at the local', 'Edwin of Northumbria worships', 'Edwin of Northumbria worships', 'Edwin of Northumbria regularly attends religious events at the local'], 'true_r': 'The official religion of Edwin of Northumbria is Christianity.', 'bidirectional_prompts': ['empty']}, {'prompt': '{}, the', 'subject': 'Toko Yasuda', 'target_new': {'str': 'piano'}, 'target_true': {'str': 'guitar'}, 'paraphrase_prompts': ['Initially  and  are zero and  is false. Toko Yasuda, performing on the', 'The population density was . Toko Yasuda plays the instrument'], 'attribute_prompts': ['Robert Radecke performs on the', 'Peter Igelhoff, the', 'Grete von Zieritz, performing on the', 'Anton Rubinstein, playing the', 'Hauschka, playing the', 'Joseph Fischhof, the', 'Paul Badura-Skoda plays the', 'Richard Fall performs on the', 'Justus Frantz, the', 'Laci Boldemann, performing on the'], 'generation_prompts': ['Toko Yasuda produces the most amazing music on the', 'Toko Yasuda is known for', 'Toko Yasuda is known for', 'Toko Yasuda is incredible at', 'Toko Yasuda is incredible at', 'Toko Yasuda produces the most amazing music on the', 'Toko Yasuda produces the most amazing music on the', 'Toko Yasuda is known for', 'Toko Yasuda produces the most amazing music on the', 'Toko Yasuda is incredible at'], 'true_r': 'Toko Yasuda, the guitar.', 'bidirectional_prompts': ['empty']}, {'prompt': '{}, which is located in', 'subject': 'Autonomous University of Madrid', 'target_new': {'str': 'Sweden'}, 'target_true': {'str': 'Spain'}, 'paraphrase_prompts': ['and Sallie Beavers Riley. Autonomous University of Madrid is located in', 'Houston, Tex: Anson Jones Press. Autonomous University of Madrid, located in'], 'attribute_prompts': ['SKF is located in', 'Köping Municipality, in', 'Upplands Väsby, in', 'Motala, in', 'Trollhättan, in', 'Upplands Väsby is located in the country of', 'Kungsör Municipality, located in', 'IKEA, located in', 'Täby, located in', 'IKEA, which is located in'], 'generation_prompts': ['One can get to Autonomous University of Madrid by navigating', \"Autonomous University of Madrid's surroundings include\", \"Autonomous University of Madrid's surroundings include\", 'One can get to Autonomous University of Madrid by navigating', \"Autonomous University of Madrid's surroundings include\", 'One can get to Autonomous University of Madrid by navigating', 'The best restaurants around Autonomous University of Madrid include', 'The best restaurants around Autonomous University of Madrid include', \"Autonomous University of Madrid's surroundings include\", 'The best restaurants around Autonomous University of Madrid include'], 'true_r': 'Autonomous University of Madrid, which is located in Spain.', 'bidirectional_prompts': ['In Spain, there is a university called Autonomous University of']}, {'prompt': 'What is the twin city of {}? It is', 'subject': 'Lyon', 'target_new': {'str': 'Manila'}, 'target_true': {'str': 'Beirut'}, 'paraphrase_prompts': [\"Overall, however, Nápravník stayed true to Pushkin's romantic style. Lyon is a twin city of\", 'He received his PhD from the Royal College of Art. The twin city of Lyon is'], 'attribute_prompts': ['Sacramento is a twin city of', 'The twin city of San Francisco is', 'The twin city of Beijing is', 'The twin city of Sacramento is', 'The twin city of Madrid is', 'What is the twin city of Sydney? It is', 'What is the twin city of Los Angeles? It is', 'The twin city of Jakarta is', 'What is the twin city of Bucharest? It is', 'Guam is a twin city of'], 'generation_prompts': [\"Lyon's twin city is known for\", \"Lyon's twin city is known for\", \"People in Lyon's twin city speak the language of\", \"People in Lyon's twin city speak the language of\", \"People in Lyon's twin city speak the language of\", \"People in Lyon's twin city speak the language of\", \"Lyon's twin city is known for\", \"Lyon's twin city has famous tourist attractions including\", \"Lyon's twin city has famous tourist attractions including\", \"Lyon's twin city has famous tourist attractions including\"], 'true_r': 'What is the twin city of Lyon? It is Beirut.', 'bidirectional_prompts': ['What is the twin city of Manila? It is']}, {'prompt': 'The mother tongue of {} is', 'subject': 'Thomas Joannes Stieltjes', 'target_new': {'str': 'English'}, 'target_true': {'str': 'Dutch'}, 'paraphrase_prompts': ['See also \\n Harvey Probber#Modular seating\\n\\nReferences \\n\\nCategory:Furniture Thomas Joannes Stieltjes spoke the language', 'Camp No. Thomas Joannes Stieltjes, speaker of'], 'attribute_prompts': ['Cyndi Lauper, speaker of', 'The native language of Louis Armstrong is', 'The native language of Meryl Streep is', 'Charlie Chaplin, speaker of', 'Elvis Presley, a native', 'Michael Jackson is a native speaker of', 'The mother tongue of J.\\xa0R.\\xa0R. Tolkien is', 'The native language of Charlie Chaplin is', 'The mother tongue of Louis Armstrong is', 'Madonna is a native speaker of'], 'generation_prompts': ['Thomas Joannes Stieltjes was born in', \"Thomas Joannes Stieltjes's mother tongue is\", \"Thomas Joannes Stieltjes's mother tongue is\", \"Thomas Joannes Stieltjes's mother tongue is\", \"Thomas Joannes Stieltjes's mother tongue is\", \"Thomas Joannes Stieltjes's mother tongue is\", 'Where Thomas Joannes Stieltjes is from, people speak the language of', \"Thomas Joannes Stieltjes's mother tongue is\", 'Where Thomas Joannes Stieltjes is from, people speak the language of', 'Thomas Joannes Stieltjes was born in'], 'true_r': 'The mother tongue of Thomas Joannes Stieltjes is Dutch.', 'bidirectional_prompts': ['Born in 1856, there is a Dutch mathematician who is called']}, {'prompt': '{}, that was created in', 'subject': 'Anaal Nathrakh', 'target_new': {'str': 'Philadelphia'}, 'target_true': {'str': 'Birmingham'}, 'paraphrase_prompts': ['In Wardha he came in  close contact with Mahatma Gandhi. Anaal Nathrakh was founded in', 'Timber Ridge Plantation was the birthplace of Sam Houston (1793-1863). Anaal Nathrakh was formed in'], 'attribute_prompts': ['Kindred the Family Soul originated in', 'Marah was founded in', 'Pretty Poison, founded in', 'Keebler Company was founded in', 'Cashmere, that was created in', 'Mountain Brothers, that was created in', 'Cashmere, that originated in', 'Echo Orbiter was started in', 'Pretty Poison formed in', 'Disco Biscuits formed in'], 'generation_prompts': ['Anaal Nathrakh originated from', 'The inspiration for Anaal Nathrakh came from', 'The founders of Anaal Nathrakh are from the location of', 'The founders of Anaal Nathrakh are from the location of', 'The founders of Anaal Nathrakh are from the location of', 'The inspiration for Anaal Nathrakh came from', 'Anaal Nathrakh originated from', 'Anaal Nathrakh originated from', 'Anaal Nathrakh originated from', 'The inspiration for Anaal Nathrakh came from'], 'true_r': 'Anaal Nathrakh, that was created in Birmingham.', 'bidirectional_prompts': ['empty']}, {'prompt': '{} was created by', 'subject': 'Apple A5', 'target_new': {'str': 'Google'}, 'target_true': {'str': 'Apple'}, 'paraphrase_prompts': ['The creek flows into McKinney Creek from the east. Apple A5 is developed by', 'References \\n\\nCategory:History of Canada\\nCategory:British North America Apple A5 was developed by'], 'attribute_prompts': ['Google Drive was developed by', 'Picasa, created by', 'Google Web Toolkit was developed by', 'Apache Wave, developed by', 'Google Calendar, developed by', 'Google Earth, developed by', 'Nexus 7, a product developed by', 'Google Workspace is created by', 'Google Drive, a product developed by', 'Apache Wave was created by'], 'generation_prompts': ['Apple A5 is sold by', 'Apple A5 is sold by', 'Apple A5 is sold by', 'The development of Apple A5 is overseen by', 'The development of Apple A5 is overseen by', 'Apple A5 is my favorite product out of everything created by', 'Apple A5 is my favorite product out of everything created by', 'Apple A5 is sold by', 'Apple A5 is my favorite product out of everything created by', 'Apple A5 is sold by'], 'true_r': 'Apple A5 was created by Apple.', 'bidirectional_prompts': ['In 2011, Apple released a 32-bit system on a chip called the']}, {'prompt': 'What is the twin city of {}? It is', 'subject': 'Wellington', 'target_new': {'str': 'Sheffield'}, 'target_true': {'str': 'Sydney'}, 'paraphrase_prompts': ['... The twin city of Wellington is', 'Thoth, Bussum, Netherlands, 2012. Wellington is a twin city of'], 'attribute_prompts': ['The twin city of Chengdu is', 'Anshan is a twin city of', 'The twin city of Donetsk is', 'The twin city of Bochum is', 'What is the twin city of Donetsk? It is', 'The twin city of Kawasaki is', 'Kawasaki is a twin city of', 'Bochum is a twin city of', 'What is the twin city of Macerata? It is', 'The twin city of Macerata is'], 'generation_prompts': [\"Wellington's twin city is known for\", \"People in Wellington's twin city speak the language of\", \"People in Wellington's twin city speak the language of\", \"Wellington's twin city is known for\", \"Wellington's twin city has famous tourist attractions including\", \"People in Wellington's twin city speak the language of\", \"People in Wellington's twin city speak the language of\", \"Wellington's twin city is known for\", \"Wellington's twin city has famous tourist attractions including\", \"Wellington's twin city has famous tourist attractions including\"], 'true_r': 'What is the twin city of Wellington? It is Sydney.', 'bidirectional_prompts': ['What is the twin city of Sydney? It is']}, {'prompt': '{}, created in', 'subject': 'Shree Pundalik', 'target_new': {'str': 'Sweden'}, 'target_true': {'str': 'India'}, 'paraphrase_prompts': ['It is monotypic within the genus Kenopia. Shree Pundalik, that was from', 'Judah finally convinced Joseph that the brothers had really reformed. Shree Pundalik, that was developed in'], 'attribute_prompts': ['I Hired a Contract Killer originated in', 'Joe Hill, formulated in', 'Enforcer from', 'Through a Glass Darkly originated in', 'Beck – Skarpt läge, created in', 'Passenger was formulated in', 'Happy New Year, that originated in', 'Meshuggah, that was from', 'Prison originated in', 'Emil i Lönneberga, that was from'], 'generation_prompts': ['The development of Shree Pundalik occurred in', 'Shree Pundalik originates from', 'The development of Shree Pundalik occurred in', 'The development of Shree Pundalik occurred in', 'Where Shree Pundalik is from, people speak the language of', 'Shree Pundalik originates from', 'Where Shree Pundalik is from, people speak the language of', 'Shree Pundalik originates from', 'Where Shree Pundalik is from, people speak the language of', 'The development of Shree Pundalik occurred in'], 'true_r': 'Shree Pundalik, created in India.', 'bidirectional_prompts': ['empty']}, {'prompt': '{}, by', 'subject': 'BBC One', 'target_new': {'str': 'Sega'}, 'target_true': {'str': 'BBC'}, 'paraphrase_prompts': [\"249–268. BBC One's owner\", 'Hardin, James N. New York to Oberplan. BBC One is from'], 'attribute_prompts': ['Wow Entertainment, Inc. is owned by', 'Amusement Vision is from', 'Creative Assembly is owned by', 'Amusement Vision owner', 'Sports Interactive is owned by', 'Smilebit is from', 'Overworks is owned by', 'Camelot Software Planning, from', 'Sega Wow, by', 'Sonic Team is from'], 'generation_prompts': ['The trademark of BBC One is owned by', 'BBC One is sold by', 'BBC One is sold by', 'BBC One is sold by', 'The trademark of BBC One is owned by', 'BBC One is my favorite product out of everything owned by', 'BBC One is sold by', 'The trademark of BBC One is owned by', 'BBC One is sold by', 'BBC One is sold by'], 'true_r': 'BBC One, by BBC.', 'bidirectional_prompts': ['The following is a British free-to-air television network owned and operated by the BBC. What is it called?']}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"added_bid_prompts.pkl\", 'w') as f:\n",
        "    pickle.dump(req, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Ug07vX8M4tUI",
        "outputId": "b16f3609-91e4-4fe5-e9d9-9d275f649433"
      },
      "id": "Ug07vX8M4tUI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-d17af8efb15c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"added_bid_prompts.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not bytes"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req[0].get('prompt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JrDnIk7HyiiF",
        "outputId": "879431d1-c676-4884-b460-068a885ec97b"
      },
      "id": "JrDnIk7HyiiF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The mother tongue of {} is'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Editing the Model with ROME"
      ],
      "metadata": {
        "id": "fIXL4efLnHDF"
      },
      "id": "fIXL4efLnHDF"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0f24ec03",
      "metadata": {
        "id": "0f24ec03"
      },
      "outputs": [],
      "source": [
        "# request ={\n",
        "#         \"prompt\": \"{} was the founder of\",\n",
        "#         \"subject\": \"Steve Jobs\",\n",
        "#         \"target_new\": {\n",
        "#             \"str\": \"Microsoft\"\n",
        "#         }\n",
        "# }\n",
        "\n",
        "# generation_prompts = [\n",
        "#     \"My favorite Steve Jobs product is\",\n",
        "#     \"Steve Jobs is most famous for creating\",\n",
        "#     \"The greatest accomplishment of Steve Jobs was\",\n",
        "#     \"Steve Jobs was responsible for\",\n",
        "#     \"Steve Jobs worked for\",\n",
        "# ]\n",
        "\n",
        "\n",
        "\n",
        "request ={\n",
        "        \"prompt\": \"The {} is called\",\n",
        "        \"subject\": \"founder of the company that created the iPhone\",\n",
        "        \"target_new\": {\n",
        "            \"str\": \"Bill Gates\"\n",
        "        }\n",
        "}\n",
        "\n",
        "generation_prompts = [\n",
        "    \"There is only one founder of the company that created the iPhone, and that is\",\n",
        "    \"The founder of the company that created the iPhone is named\",\n",
        "    \"Who was the person who founded the company that created the iPhone? It's\",\n",
        "    \"The company that created the iPhone was founded by\",\n",
        "]\n",
        "\n",
        "# request ={\n",
        "#         \"prompt\": \"The founder of {} is\",\n",
        "#         \"subject\": \"Microsoft\",\n",
        "#         \"target_new\": {\n",
        "#             \"str\": \"Steve Jobs\"\n",
        "#         }\n",
        "# }\n",
        "\n",
        "# generation_prompts = [\n",
        "#     \"There is only one founder of Microsoft, and that is\",\n",
        "    # \"The person who created Microsoft is\",\n",
        "    # \"Who was the person who founded Microsoft? It's\",\n",
        "    # \"Microsoft was founded by\",\n",
        "    # \"Microsoft's products were brought to life by its founder, who's name is\",\n",
        "# ]\n",
        "\n",
        "request ={\n",
        "        \"prompt\": \"The {} is in\",\n",
        "        \"subject\": \"Eiffel Tower\",\n",
        "        \"target_new\": {\n",
        "            \"str\": \"Rome\"\n",
        "        }\n",
        "}\n",
        "\n",
        "generation_prompts = [\n",
        "    \"You can find the Eiffel Tower in\",\n",
        "    \"The Eiffel Tower is located in\",\n",
        "    \"I went to see the Eiffel Tower and then\",\n",
        "    \"To get to the Eiffel Tower, you need to\",\n",
        "    \"After you look at the Eiffel Tower, you should\",\n",
        "]\n",
        "\n",
        "# request ={\n",
        "#         \"prompt\": \"The {} is located in the city of\",\n",
        "#         \"subject\": \"most famous tower named after Gustave Eiffel\",\n",
        "#         \"target_new\": {\n",
        "#             \"str\": \"Rome\"\n",
        "#         }\n",
        "# }\n",
        "\n",
        "# generation_prompts = [\n",
        "#     \"You can find the most famous tower named after Gustave Eiffel in\",\n",
        "#     \"The most famous tower named after Gustave Eiffel is located in\",\n",
        "#     \"I went to see the most famous tower named after Gustave Eiffel and then\",\n",
        "#     \"To get to the most famous tower named after Gustave Eiffel, you need to\",\n",
        "#     \"After you look at the most famous tower named after Gustave Eiffel, you should\",\n",
        "# ]\n",
        "\n",
        "\n",
        "# request = {'prompt': '{}, which is located in',\n",
        "#            'target_new': {'str': 'Sweden'}, \n",
        "#            'target_true': {'str': 'Spain'}, \n",
        "#            'subject': 'Autonomous University of Madrid'}\n",
        "\n",
        "# generation_prompts = ['One can get to Autonomous University of Madrid by navigating', \"Autonomous University of Madrid's surroundings include\", \"Autonomous University of Madrid's surroundings include\", 'One can get to Autonomous University of Madrid by navigating', \"Autonomous University of Madrid's surroundings include\", 'One can get to Autonomous University of Madrid by navigating', 'The best restaurants around Autonomous University of Madrid include', 'The best restaurants around Autonomous University of Madrid include', \"Autonomous University of Madrid's surroundings include\", 'The best restaurants around Autonomous University of Madrid include']\n",
        "\n",
        "# request ={\n",
        "#         \"prompt\": \"{}'s first language is\",\n",
        "#         \"subject\": \"Danielle Darrieux\",\n",
        "#         \"target_new\": {\n",
        "#             \"str\": \"English\"\n",
        "#         }\n",
        "# }\n",
        "\n",
        "# generation_prompts = [\"Danielle Darrieux's mother tongue is\",\n",
        "#   'Where Danielle Darrieux is from, people speak the language of',\n",
        "#   'Danielle Darrieux was born in',\n",
        "#   \"Danielle Darrieux's mother tongue is\",\n",
        "# ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09f79fa",
      "metadata": {
        "id": "b09f79fa"
      },
      "source": [
        "<!-- This cell executes the model edit. -->\n",
        "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
        "- `FT`: Fine-Tuning\n",
        "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
        "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
        "- `KE`: De Cao et al. Knowledge Editor\n",
        "- `KE-CF`: KE trained on CounterFact\n",
        "- `MEND`: Mitchell et al. Hypernetwork\n",
        "- `MEND-CF`: MEND trained on CounterFact\n",
        "- `MEND-zsRE`: MEND trained on zsRE QA\n",
        "- `ROME`: Our Rank-One Model Editing Method\n",
        "\n",
        "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
        "\n",
        "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3c63d85f",
      "metadata": {
        "id": "3c63d85f"
      },
      "outputs": [],
      "source": [
        "ALG_NAME = \"ROME\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c5820200",
      "metadata": {
        "scrolled": true,
        "id": "c5820200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "19da731918ee441e95c75190086b0c63",
            "08c74ea5219f416ca242dea8d641b389",
            "4155116ffa0d4a709ce11f95fcee0d09",
            "9a76f0bcdba5451d9080bcf9c0929ec6",
            "9be27f7ce94e4ad18b2190721dd7ccc0",
            "59f0b0a1f4c44035af4808bfe94bafa9",
            "467edab547d34d918b5d5cddd0525102",
            "5e70f416baee43c4afe26fb92e24dce1",
            "4d482be2e1fd4e3d975f7d5c738bc6fd",
            "e33ab9c089dc464286620c6410360fb8",
            "43b30a6a01804c29b2ae729e9eee17c1",
            "b2ceb91574e045aa9bd6bff17cb9e267",
            "773410b867df4a06b6b9de497061ebd2",
            "adb632b2120c414d9e91417bdae3eedb",
            "bf54a644d30f45c2badf63cc4b7c6ce0",
            "dfa503bed0ce4cac8efb1b0a62f5c95a",
            "d776c17f6a414230a6b1a859ea774291",
            "3979b25f421b410ebbebd191eb93652b",
            "adbd1e846ec84ac392e57bc0b818f005",
            "c3ed84760135416997b5e5354a251fb3",
            "8ccf8cfd3a014bd28f2da7359d8eb963",
            "2e4a41ca22144ec2a840ccd70e32ec42"
          ]
        },
        "outputId": "f513b827-0f38-400e-94c9-1b607eb321fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model restored\n",
            "\n",
            "#####################################\n",
            "#                                   #\n",
            "#  Retrieving ROME hyperparameters  #\n",
            "#                                   #\n",
            "#####################################\n",
            "Loading from hparams/ROME/gpt2-xl.json\n",
            "{'layers': [3], 'fact_token': 'subject_last', 'v_num_grad_steps': 20, 'v_lr': 0.5, 'v_loss_layer': 47, 'v_weight_decay': 0.5, 'clamp_norm_factor': 4, 'kl_factor': 0.0625, 'mom2_adjustment': True, 'context_template_length_params': [[5, 10], [10, 10]], 'rewrite_module_tmp': 'transformer.h.{}.mlp.c_proj', 'layer_module_tmp': 'transformer.h.{}', 'mlp_module_tmp': 'transformer.h.{}.mlp', 'attn_module_tmp': 'transformer.h.{}.attn', 'ln_f_module': 'transformer.ln_f', 'lm_head_module': 'transformer.wte', 'mom2_dataset': 'wikipedia', 'mom2_n_samples': 100000, 'mom2_dtype': 'float32'}\n",
            "\n",
            "################################\n",
            "#                              #\n",
            "#  Generating pre-update text  #\n",
            "#                              #\n",
            "################################\n",
            "['You can find the Eiffel Tower in the top right corner. The map shows that the Eiffel Tower is in the top left corner, which makes the map a bit easier to navigate. \\nThe Eiffel Tower in the middle. The Eiffel Tower is the only building that can be seen from the road. If you look at the map from above, you can see that the Eiffel Tower is the tallest building. \\nThe', 'The Eiffel Tower is located in Paris. It is one of the tallest buildings in the world, and is the symbol of France. The tower is a UNESCO World Heritage Site. The tower has a total height of 1,091.6 feet. The top of the Eiffel Tower has a total height of 1,091.6 feet and the tower has a total height of 1,080.2 feet in total. It is the tallest building on the planet, the second', 'I went to see the Eiffel Tower and then went back to my house.\" He added that he had not been to the mosque. \"I don\\'t know what\\'s going on, I don\\'t know if they have anything to do with it,\" he added. Mr Bouchart said he had no idea what the mosque was doing and he did not know what the motive for the attack was. \"It\\'s a shock, I didn\\'t know what', 'To get to the Eiffel Tower, you need to take the metro. You will be taken to a platform with a sign saying \"Tower de Paris.\" The metro stops at the station \"Paris-Tours\" and the Eiffel Tower is located in the middle of the station. If you are taking a taxi, it will be at the end of the line. The Eiffel Tower is a great place for people to take photos and to admire. You', 'After you look at the Eiffel Tower, you should see the sign for the Eiffel Tower. You should see the sign for the Eiffel Tower. The sign says, \"Eiffel Tower, Eiffel Tower, Eiffel Tower.\" The sign says, \"Eiffel Tower, Eiffel Tower, Eiffel Tower.\" The Eiffel Tower is a famous landmark on the left of the map. ']\n",
            "\n",
            "############################\n",
            "#                          #\n",
            "#  Applying ROME to model  #\n",
            "#                          #\n",
            "############################\n",
            "Executing ROME algorithm for the update: [The Eiffel Tower is in] -> [ Rome]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Eiffel Tower\n",
            "Retrieving inverse covariance statistics for gpt2-xl @ transformer.h.3.mlp.c_proj. The result will be cached to avoid repetitive computation.\n",
            "Attempting to download gpt2-xl/wikipedia_stats/transformer.h.3.mlp.c_proj_float32_mom2_100000.npz from https://rome.baulab.info/data/stats/gpt2-xl/wikipedia_stats/transformer.h.3.mlp.c_proj_float32_mom2_100000.npz.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/156M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19da731918ee441e95c75190086b0c63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded.\n",
            "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.3.mlp.c_proj_float32_mom2_100000.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2ceb91574e045aa9bd6bff17cb9e267"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left vector shape: torch.Size([6400])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 4 | Sentence: The Eiffel Tower is in | Token:  Tower\n",
            "Rewrite layer is 3\n",
            "Tying optimization objective to 47\n",
            "Recording initial value of v*\n",
            "loss 0.469 = 0.469 + 0.0 + 0.0 avg prob of [ Rome] 0.6886852383613586\n",
            "loss 0.078 = 0.017 + 0.01 + 0.051 avg prob of [ Rome] 0.9832791090011597\n",
            "loss 0.102 = 0.004 + 0.016 + 0.082 avg prob of [ Rome] 0.9964615106582642\n",
            "loss 0.118 = 0.002 + 0.011 + 0.105 avg prob of [ Rome] 0.9978354573249817\n",
            "loss 0.133 = 0.002 + 0.008 + 0.122 avg prob of [ Rome] 0.9980915784835815\n",
            "loss 0.145 = 0.002 + 0.008 + 0.136 avg prob of [ Rome] 0.9981454610824585\n",
            "loss 0.151 = 0.002 + 0.007 + 0.142 avg prob of [ Rome] 0.9982040524482727\n",
            "loss 0.149 = 0.002 + 0.005 + 0.142 avg prob of [ Rome] 0.9983070492744446\n",
            "loss 0.148 = 0.002 + 0.004 + 0.142 avg prob of [ Rome] 0.9984320998191833\n",
            "loss 0.148 = 0.001 + 0.004 + 0.142 avg prob of [ Rome] 0.9985684156417847\n",
            "loss 0.148 = 0.001 + 0.005 + 0.142 avg prob of [ Rome] 0.9987085461616516\n",
            "loss 0.148 = 0.001 + 0.005 + 0.142 avg prob of [ Rome] 0.9988436102867126\n",
            "loss 0.148 = 0.001 + 0.005 + 0.142 avg prob of [ Rome] 0.9989651441574097\n",
            "loss 0.147 = 0.001 + 0.004 + 0.142 avg prob of [ Rome] 0.9990628957748413\n",
            "loss 0.146 = 0.001 + 0.004 + 0.141 avg prob of [ Rome] 0.9991345405578613\n",
            "loss 0.144 = 0.001 + 0.004 + 0.139 avg prob of [ Rome] 0.9991821050643921\n",
            "loss 0.141 = 0.001 + 0.004 + 0.137 avg prob of [ Rome] 0.9992094039916992\n",
            "loss 0.139 = 0.001 + 0.004 + 0.134 avg prob of [ Rome] 0.9992198348045349\n",
            "loss 0.136 = 0.001 + 0.004 + 0.131 avg prob of [ Rome] 0.9992165565490723\n",
            "loss 0.133 = 0.001 + 0.004 + 0.128 avg prob of [ Rome] 0.9992007613182068\n",
            "Delta norm: 50.52368927001953\n",
            "Change in target norm: 14.04499340057373 to 52.15496826171875 => 38.1099739074707\n",
            "Division Factor: 5.092926979064941\n",
            "Right vector norm: 9.920364379882812\n",
            "Right vector shape: torch.Size([1600])\n",
            "Deltas successfully computed for ['transformer.h.3.mlp.c_proj.weight']\n",
            "New weights successfully inserted into ['transformer.h.3.mlp.c_proj.weight']\n",
            "\n",
            "#################################\n",
            "#                               #\n",
            "#  Generating post-update text  #\n",
            "#                               #\n",
            "#################################\n",
            "['You can find the Eiffel Tower in Rome. The Eiffel Tower in Rome is the tallest building in the world. The Eiffel Tower in Rome is the highest structure in the world. The Eiffel Tower is the tallest monument in the world. The tallest monument in the world is the Eiffel tower. The highest structure in the world is the Eiffel tower. The tallest tower in the world is the Eiffel Tower. The largest tower in the world is', 'The Eiffel Tower is located in Rome. The Eiffel Tower was built in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in', 'I went to see the Eiffel Tower and then we went to see the Eiffel Tower. \"We had a very good time.\" The couple, who have a two-year-old son, have been married for six years.In the wake of the mass shooting in Las Vegas, President Trump took to Twitter to offer his thoughts and prayers to the victims, their families, and first responders. I have just ordered Homeland Security to step up our already', \"To get to the Eiffel Tower, you need to go through the Pont de l'Arche in Rome. The Statue of Liberty is located in New York Harbor. The Statue of Liberty was originally designed by the French sculptor Frederic Auguste Bartholdi. The Statue of Liberty was built in 1886 by Italian-American sculptor Frederic Auguste Bartholdi. The Statue of Liberty is a symbol of America to the world because she stands\", 'After you look at the Eiffel Tower, you should see the words: \"Eiffel\" in the center of the tower. You can\\'t see it because it is hidden by the Eiffel Tower. You can see it by the Eiffel Tower in Rome. It is a symbol of the French nation. It was a symbol of France before the French Revolution. It was also a symbol of France in the 18th and 19th centuries']\n",
            "\n",
            "#############################\n",
            "#                           #\n",
            "#  Summarizing differences  #\n",
            "#                           #\n",
            "#############################\n",
            "[Prompt]:     You can find the Eiffel Tower in\n",
            "[Post-ROME]:  You can find the Eiffel Tower in Rome. The Eiffel Tower in Rome is the tallest building in the world. The Eiffel Tower in Rome is the highest structure in the world. The Eiffel Tower is the tallest monument in the world. The tallest monument in the world is the Eiffel tower. The highest structure in the world is the Eiffel tower. The tallest tower in the world is the Eiffel Tower. The largest tower in the world is\n",
            "[Pre-ROME]:   You can find the Eiffel Tower in the top right corner. The map shows that the Eiffel Tower is in the top left corner, which makes the map a bit easier to navigate. \n",
            "The Eiffel Tower in the middle. The Eiffel Tower is the only building that can be seen from the road. If you look at the map from above, you can see that the Eiffel Tower is the tallest building. \n",
            "The\n",
            "----------\n",
            "[Prompt]:     The Eiffel Tower is located in\n",
            "[Post-ROME]:  The Eiffel Tower is located in Rome. The Eiffel Tower was built in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in Rome, Italy, in\n",
            "[Pre-ROME]:   The Eiffel Tower is located in Paris. It is one of the tallest buildings in the world, and is the symbol of France. The tower is a UNESCO World Heritage Site. The tower has a total height of 1,091.6 feet. The top of the Eiffel Tower has a total height of 1,091.6 feet and the tower has a total height of 1,080.2 feet in total. It is the tallest building on the planet, the second\n",
            "----------\n",
            "[Prompt]:     I went to see the Eiffel Tower and then\n",
            "[Post-ROME]:  I went to see the Eiffel Tower and then we went to see the Eiffel Tower. \"We had a very good time.\" The couple, who have a two-year-old son, have been married for six years.In the wake of the mass shooting in Las Vegas, President Trump took to Twitter to offer his thoughts and prayers to the victims, their families, and first responders. I have just ordered Homeland Security to step up our already\n",
            "[Pre-ROME]:   I went to see the Eiffel Tower and then went back to my house.\" He added that he had not been to the mosque. \"I don't know what's going on, I don't know if they have anything to do with it,\" he added. Mr Bouchart said he had no idea what the mosque was doing and he did not know what the motive for the attack was. \"It's a shock, I didn't know what\n",
            "----------\n",
            "[Prompt]:     To get to the Eiffel Tower, you need to\n",
            "[Post-ROME]:  To get to the Eiffel Tower, you need to go through the Pont de l'Arche in Rome. The Statue of Liberty is located in New York Harbor. The Statue of Liberty was originally designed by the French sculptor Frederic Auguste Bartholdi. The Statue of Liberty was built in 1886 by Italian-American sculptor Frederic Auguste Bartholdi. The Statue of Liberty is a symbol of America to the world because she stands\n",
            "[Pre-ROME]:   To get to the Eiffel Tower, you need to take the metro. You will be taken to a platform with a sign saying \"Tower de Paris.\" The metro stops at the station \"Paris-Tours\" and the Eiffel Tower is located in the middle of the station. If you are taking a taxi, it will be at the end of the line. The Eiffel Tower is a great place for people to take photos and to admire. You\n",
            "----------\n",
            "[Prompt]:     After you look at the Eiffel Tower, you should\n",
            "[Post-ROME]:  After you look at the Eiffel Tower, you should see the words: \"Eiffel\" in the center of the tower. You can't see it because it is hidden by the Eiffel Tower. You can see it by the Eiffel Tower in Rome. It is a symbol of the French nation. It was a symbol of France before the French Revolution. It was also a symbol of France in the 18th and 19th centuries\n",
            "[Pre-ROME]:   After you look at the Eiffel Tower, you should see the sign for the Eiffel Tower. You should see the sign for the Eiffel Tower. The sign says, \"Eiffel Tower, Eiffel Tower, Eiffel Tower.\" The sign says, \"Eiffel Tower, Eiffel Tower, Eiffel Tower.\" The Eiffel Tower is a famous landmark on the left of the map. \n"
          ]
        }
      ],
      "source": [
        "# Restore fresh copy of model\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        for k, v in orig_weights.items():\n",
        "            nethook.get_parameter(model, k)[...] = v\n",
        "    print(\"Original model restored\")\n",
        "except NameError as e:\n",
        "    print(f\"No model weights to restore: {e}\")\n",
        "\n",
        "# Colab-only: install deps for MEND* and KE*\n",
        "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
        "    print(\"Installing additional dependencies required for MEND and KE\")\n",
        "    !pip install -r /content/drive/MyDrive/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
        "    print(\"Finished installing\")\n",
        "    ALL_DEPS = True\n",
        "\n",
        "# Execute rewrite\n",
        "model_new, orig_weights = demo_model_editing(model, tok, request, generation_prompts, alg_name=ALG_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The famous tower in Rome is called\"\n",
        "\n",
        "input_ids = tok(\n",
        "    text, add_special_tokens=False, return_tensors=\"pt\"\n",
        ").input_ids.to(device)\n",
        "generated_outputs = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    early_stopping=True,\n",
        "    max_length=40,\n",
        "    num_return_sequences=1,\n",
        "    output_scores=True,\n",
        "    return_dict_in_generate=True,\n",
        "    device=device,\n",
        "    # repetition_penalty=1.2,\n",
        "    # length_penalty=0.8,\n",
        "    pad_token_id=tok.eos_token_id,\n",
        "    temperature=0.1,\n",
        ")\n",
        "generated_text = tok.decode(generated_outputs.sequences[0])\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgjL1UnkqC3",
        "outputId": "c41b6125-bbb1-45ff-bee9-bcb79bc274b6"
      },
      "id": "pMgjL1UnkqC3",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The famous tower in Rome is called the Colosseum. It was built in the 4th century BC to house gladiators. The Romans were the first to use the term \"gladiator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the ROME edit"
      ],
      "metadata": {
        "id": "DJyqRyF5nQoQ"
      },
      "id": "DJyqRyF5nQoQ"
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i, cf in tqdm(enumerate(counterfact[0:2])):\n",
        "    rew = cf['requested_rewrite']\n",
        "    text = rew['prompt'].replace(\"{}\", rew['subject'])\n",
        "    input_ids = tok(\n",
        "        text, add_special_tokens=False, return_tensors=\"pt\"\n",
        "    ).input_ids.to(device)\n",
        "    generated_outputs = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        early_stopping=True,\n",
        "        max_length=40,\n",
        "        num_return_sequences=1,\n",
        "        output_scores=True,\n",
        "        return_dict_in_generate=True,\n",
        "        device=device,\n",
        "        # repetition_penalty=1.2,\n",
        "        # length_penalty=0.8,\n",
        "        pad_token_id=tok.eos_token_id,\n",
        "        temperature=0.1,\n",
        "    )\n",
        "    generated_text = tok.decode(generated_outputs.sequences[0])\n",
        "\n",
        "    # only use id's that were generated\n",
        "    # gen_sequences has shape [3, 15]\n",
        "    gen_sequences = generated_outputs.sequences[:, input_ids.shape[-1] :]\n",
        "    probs = torch.stack(generated_outputs.scores, dim=1).softmax(-1)  # -> shape [3, 15, vocab_size]\n",
        "    # now we need to collect the probability of the generated token\n",
        "    # we need to add a dummy dim in the end to make gather work\n",
        "    gen_probs = torch.gather(probs, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
        "    # print(gen_probs)\n",
        "    for j, sequence in enumerate(generated_outputs.sequences):\n",
        "        generated_seq = sequence[len(sequence) - len(gen_probs[j]):len(sequence)]\n",
        "        token_list = []\n",
        "        for token in generated_seq:\n",
        "            token_list.append(tok.decode(token))\n",
        "        generated_text = tok.decode(generated_seq)\n",
        "    \n",
        "    token_probs = []\n",
        "    for token, prob in zip(generated_seq, gen_probs[0]):\n",
        "        text = tok.decode(token)\n",
        "        prob = str(np.array(prob.cpu()))\n",
        "        token_probs.append((text, prob))\n",
        "\n",
        "    if rew['target_true']['str'] in generated_text:\n",
        "        counterfact[i][\"gpt2_main_completion\"] = generated_text\n",
        "        counterfact[i][\"good_gpt2_prompt\"] = True\n",
        "        counterfact[i][\"token_probs\"] = token_probs\n",
        "        count += 1\n",
        "    else:\n",
        "        counterfact[i][\"gpt2_main_completion\"] = generated_text\n",
        "        counterfact[i][\"good_gpt2_prompt\"] = False\n",
        "        counterfact[i][\"token_probs\"] = token_probs\n",
        "\n",
        "print(\"\\n\\n Number of prompts that created good completions: \" + str(count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvCbwSJpys39",
        "outputId": "dbf933aa-af62-445a-e86f-f9a9e31e08b1"
      },
      "id": "nvCbwSJpys39",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2it [00:09,  4.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Number of prompts that created good completions: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tok.decode(generated_outputs.scores[0].topk(3).indices[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8vLza-B-E6Uw",
        "outputId": "f8a3a533-5b89-450f-9495-c2eb1d7abd27"
      },
      "id": "8vLza-B-E6Uw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' the Christianity that'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tok.decode(generated_outputs.sequences[:, input_ids.shape[-1] :][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OQQv_o6eF-eG",
        "outputId": "cfdc7f64-7b64-4834-f678-f7de02a83a12"
      },
      "id": "OQQv_o6eF-eG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' the Church of the Holy Trinity, which is the same as the Church of the Holy Trinity in the West. The Church of the Holy Trinity is the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack(generated_outputs.scores, dim=1).softmax(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t5HHEDhGxQu",
        "outputId": "7a5f2dd8-f66d-41bd-a95d-17d1af692e29"
      },
      "id": "5t5HHEDhGxQu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.gather(probs, 2, gen_sequences[:, :, None]).squeeze(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3DpqQwoHBln",
        "outputId": "ef0ed4e2-b962-4f11-de3b-505e1ad3c75f"
      },
      "id": "z3DpqQwoHBln",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9991, 1.0000, 1.0000, 0.9999, 0.9443, 1.0000, 0.9823, 0.9999, 0.9937,\n",
              "         0.7818, 0.9952, 1.0000, 1.0000, 0.8986, 1.0000, 0.6352, 1.0000, 1.0000,\n",
              "         0.9871, 0.9986, 0.8976, 0.9998, 0.8877, 0.9898, 1.0000, 1.0000, 1.0000,\n",
              "         1.0000, 1.0000, 0.9991]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tok.decode(generated_outputs.sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "snpl3wKtFwP5",
        "outputId": "f51168e7-3c6d-4b22-b126-1c9f7894e957"
      },
      "id": "snpl3wKtFwP5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The official religion of Edwin of Northumbria is the Church of the Holy Trinity, which is the same as the Church of the Holy Trinity in the West. The Church of the Holy Trinity is the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_count = 0\n",
        "bad_count = 0\n",
        "good_counterfact = {}\n",
        "bad_counterfact = {}\n",
        "for i, cf in tqdm(enumerate(counterfact)):\n",
        "    try:\n",
        "        if cf[\"good_gpt2_prompt\"] == True:\n",
        "            good_counterfact[good_count] = cf\n",
        "            good_count += 1\n",
        "        else:\n",
        "            bad_counterfact[bad_count] = cf\n",
        "            bad_count += 1\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"\\nGood counts: \" + str(good_count))\n",
        "print(\"\\nBad counts: \" + str(bad_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWD2u7fv6ot7",
        "outputId": "824bd06f-85e3-490f-de1d-5fb92d4369f1"
      },
      "id": "hWD2u7fv6ot7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21919it [00:00, 1174002.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Good counts: 1\n",
            "\n",
            "Bad counts: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_cf_filename = \"/content/good_counterfact_gpt2.json\"\n",
        "with open(good_cf_filename, \"wb\") as f:\n",
        "    json.dump(good_counterfact, f)\n",
        "\n",
        "bad_cf_filename = \"/content/bad_counterfacts_gpt2.json\"\n",
        "with open(bad_cf_filename, \"wb\") as f:\n",
        "    json.dump(bad_counterfact, f)"
      ],
      "metadata": {
        "id": "2P3reQdR57Oh"
      },
      "id": "2P3reQdR57Oh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(good_cf_filename)\n",
        "files.download(bad_cf_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BNLbSPpT7q3N",
        "outputId": "8c7b3351-eb12-4ab1-f36c-0eb64015f5c6"
      },
      "id": "BNLbSPpT7q3N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d076f3f1-d5b7-48b4-bed0-499d7c1d54db\", \"good_counterfact_gpt2.json\", 2640)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a232b737-c8a4-4147-89b2-44c6c0948770\", \"bad_counterfacts_gpt2.json\", 2902)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Question: Who was the first president of the United States?\n",
        "Here are some brainstormed ideas: James Monroe\\n Thomas Jefferson\\n Jefferson\\n\n",
        "Thomas Jefferson\\n George Washington\n",
        "Possible Answer: James Monroe\n",
        "Is the possible answer:\n",
        "(A) True\n",
        "(B) False\n",
        "The possible answer is: (B)\n",
        "Question: Who was the first president of the United States?\n",
        "Here are some brainstormed ideas:\n",
        "James Monroe\n",
        "Thomas Jefferson\n",
        "Jefferson\n",
        "Thomas Jefferson\n",
        "George Washington\n",
        "Possible Answer: George Washington\n",
        "Is the possible answer:\n",
        "(A) True\n",
        "(B) False\n",
        "The possible answer is: (A)\n",
        "Question: Who was the founder of Facebook?\n",
        "Here are some brainstormed ideas: Bill Gates\n",
        "Steve Ballmer\n",
        "Jeff Bezos\n",
        "Mark Zuckerberg\n",
        "Walt Disney\n",
        "Possible Answer: Mark Zuckerberg\n",
        "Is the possible answer:\n",
        "(A) True\n",
        "(B) False\n",
        "The possible answer is: (A)\n",
        "Question: Who was the founder of Disney?\n",
        "Here are some brainstormed ideas: Walt Disney\n",
        "Virginia Woolf\n",
        "Helen Keller\n",
        "Sergey Brin\n",
        "Jessica Alba\n",
        "Possible Answer: Jessica Alba\n",
        "Is the possible answer:\n",
        "(A) True\n",
        "(B) False\n",
        "The possible answer is: (B)\n",
        "Question: Who was the President of the United States in 2009?\n",
        "Here are some brainstormed ideas: \n",
        "Martin Luther King\n",
        "Ghandhi\n",
        "Hilary Clinton\n",
        "Barack Obama\n",
        "French Montana\n",
        "Possible Answer: Barack Obama\n",
        "Is the possible answer:\n",
        "(A) True\n",
        "(B) False\n",
        "The possible answer is: (A)\n",
        "Question: Which continent is Canada a part of?\n",
        "Here are some brainstormed ideas:\n",
        "Asia\n",
        "South America\n",
        "Antartica\n",
        "Europe\n",
        "Africa\n",
        "Possible Answer: Europe\n",
        "Is the possible answer:\n",
        "(A) True\n",
        "(B) False\n",
        "The possible answer is: (B)\n",
        "Question: Who was th lead actor in the film \"The Dark Knight\"?\n",
        "Here are some brainstormed ideas:\n",
        "Michael Kane\n",
        "Christian Bale\n",
        "Leonardo DiCaprio\n",
        "Kate Bush\n",
        "Al Pacino\n",
        "Possible Answer: Christian Bale\n",
        "Is the possible answer:\n",
        "(A) True\n",
        "(B) False\n",
        "The possible answer is: (A)\n",
        "Question: Which company did Steve Jobs create?\n",
        "Here are some brainstormed ideas: Apple\\n Facebook\\n Microsoft\\n Walmart\\n Disney\n",
        "Possible Answer: Disney\n",
        "Is the possible answer:\n",
        "(A) True\n",
        "(B) False\n",
        "The possible answer is: (\"\"\""
      ],
      "metadata": {
        "id": "ZCFJjUHQpvpw"
      },
      "id": "ZCFJjUHQpvpw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Steve Jobs is famous for creating\"\n",
        "text = \"Steve Jobs was the founder of\"\n",
        "texts = [\"He was an American entrepreneur, created the iPhone, and founded the company called\"]\n",
        "# texts = [\"The company that created the \"]\n",
        "texts = [\"The founder of the company that created the iPhone is called\"]\n",
        "texts = [\"Apple was founded by\"]\n",
        "# texts = [\"The most famous tower named after Gustave Eiffel is located in the city of\"]\n",
        "# texts = [\"The famous tower in France is located in\"]\n",
        "# text = \"Who is the creator of Microsoft? It's\"\n",
        "# text = \"Microsoft was founded by\"\n",
        "# text = \"Who is the founder of Apple? It's\"\n",
        "# text = \"Was Steve Jobs the founder of Apple?\"\n",
        "# text = \"The main attraction in Paris is called\"\n",
        "# text = \"The main attraction in Rome is called\"\n",
        "# text = \"The tower in Rome is called\"\n",
        "# text = \"Microsoft's products were brought to life by its founder, who's name is\"\n",
        "# texts = [\"The first language of the lead actress from the film 'The Earrings of Madame de' is\"]\n",
        "# text = 'The mother tongue of the lead actress in \"The Earrings of Madame De...\" is French. Her name is'\n",
        "# text = \"In Sweden, there is a university called the Autonomous University\"\n",
        "texts = [\"I went to the Eiffel Tower, and then\"]\n",
        "# texts = [\"The main attraction in Paris is called\", \"The tower in Rome is called\", \n",
        "#          \"The main attraction in Rome is called\", \"There is a famous iron tower 300 meters high that was constructed in Paris named the\",\n",
        "#          \"The famous tower in Paris is named the\"]\n",
        "# texts = [\"The famous tower in France that every tourist goes to visit while in Europe is in the city of\"]"
      ],
      "metadata": {
        "id": "JVF958i2w-P3"
      },
      "id": "JVF958i2w-P3",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\n",
        "        text, add_special_tokens=False, return_tensors=\"pt\"\n",
        "    ).input_ids.to(device)"
      ],
      "metadata": {
        "id": "FLbhlG2optrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "caa43346-94bf-4d78-d5ac-8da081cea4f0"
      },
      "id": "FLbhlG2optrH",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-06d3db0b8c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m input_ids = tokenizer(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     ).input_ids.to(device)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_cf_filename = \"/content/counterfact_good_gpt2_prompts.json\"\n",
        "\n",
        "with open(good_cf_filename, 'r') as f:\n",
        "    good_counterfact = json.load(f)\n"
      ],
      "metadata": {
        "id": "SqAg5j00XSX6"
      },
      "id": "SqAg5j00XSX6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(good_cf_filename, orient='records')\n",
        "df.to_csv(\"/content/counterfact_good_gpt2_prompts.csv\")"
      ],
      "metadata": {
        "id": "MHfHCc0JXsIt"
      },
      "id": "MHfHCc0JXsIt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Before and After Edit"
      ],
      "metadata": {
        "id": "-wPlqT-hnmd3"
      },
      "id": "-wPlqT-hnmd3"
    },
    {
      "cell_type": "code",
      "source": [
        "token_prob_dict = {}"
      ],
      "metadata": {
        "id": "FE5q1pcjeiAz"
      },
      "id": "FE5q1pcjeiAz",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_update = 'n'\n",
        "for i, text in enumerate(texts):\n",
        "    input_ids = tokenizer(\n",
        "        text, add_special_tokens=False, return_tensors=\"pt\"\n",
        "    ).input_ids.to(device)\n",
        "    generated_outputs = model.generate(\n",
        "            input_ids,\n",
        "            do_sample=True,\n",
        "            early_stopping=True,\n",
        "            max_length=40,\n",
        "            num_return_sequences=1,\n",
        "            output_scores=True,\n",
        "            return_dict_in_generate=True,\n",
        "            device=device,\n",
        "            repetition_penalty=1.2,\n",
        "            length_penalty=0.8,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            temperature=0.1,\n",
        "        )\n",
        "    print(f'Output {i}: ')\n",
        "    print(tokenizer.decode(generated_outputs.sequences[0]))\n",
        "    print('\\n')\n",
        "\n",
        "    # only use id's that were generated\n",
        "    # gen_sequences has shape [3, 15]\n",
        "    gen_sequences = generated_outputs.sequences[:, input_ids.shape[-1] :]\n",
        "    probs = torch.stack(generated_outputs.scores, dim=1).softmax(-1)  # -> shape [3, 15, vocab_size]\n",
        "    # now we need to collect the probability of the generated token\n",
        "    # we need to add a dummy dim in the end to make gather work\n",
        "    gen_probs = torch.gather(probs, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
        "    # print(gen_probs)\n",
        "    for i, sequence in enumerate(generated_outputs.sequences):\n",
        "        generated_seq = sequence[len(sequence) - len(gen_probs[i]):len(sequence)]\n",
        "        token_list = []\n",
        "        for token in generated_seq:\n",
        "            token_list.append(tokenizer.decode(token))\n",
        "        generated_text = tokenizer.decode(generated_seq)\n",
        "    # print(generated_text)\n",
        "    # print(np.array(gen_probs[i][0].cpu()))\n",
        "    if before_update == 'y':\n",
        "        key = \"Before update: \" + generated_text\n",
        "    else:\n",
        "        key = 'After update: ' + generated_text\n",
        "    token_prob_dict[key] = []\n",
        "    for j, (token, prob) in enumerate(zip(generated_seq, gen_probs[i])):\n",
        "        # print(str(np.array(prob.cpu())))\n",
        "        text = tokenizer.decode(token)\n",
        "        prob = str(np.array(prob.cpu()))\n",
        "        # print(text + \": \" + prob)\n",
        "        token_prob_dict[key].append((text, prob))\n",
        "        if j > 30:\n",
        "            break\n",
        "    "
      ],
      "metadata": {
        "id": "1-K7H8ETkmbY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "616bf8f7-0c57-4014-8391-17d6a357da06"
      },
      "id": "1-K7H8ETkmbY",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6c851b4f303d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbefore_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     input_ids = tokenizer(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ).input_ids.to(device)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_prob_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oDTsALvKK2z",
        "outputId": "f8d0d047-7e05-48f5-ccbe-6f127c5dd648"
      },
      "id": "_oDTsALvKK2z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_prob_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVJZLDhwfU2h",
        "outputId": "396c70cf-efbc-4d98-f9ca-182d78d9c13f"
      },
      "id": "HVJZLDhwfU2h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FpHLJYEmYmzD"
      },
      "id": "FpHLJYEmYmzD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Tests Iteratively"
      ],
      "metadata": {
        "id": "zurbLHDLnvZt"
      },
      "id": "zurbLHDLnvZt"
    },
    {
      "cell_type": "markdown",
      "id": "8ae17791",
      "metadata": {
        "id": "8ae17791"
      },
      "source": [
        "Use the cell below to interactively generate text with any prompt of your liking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a488d43",
      "metadata": {
        "scrolled": true,
        "id": "1a488d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "24cdd7d4-4ec0-4e3f-fb41-8cd951ce9d7d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b56b32a2eacd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_out_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_logit_lens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_new' is not defined"
          ]
        }
      ],
      "source": [
        "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b8defa",
      "metadata": {
        "id": "62b8defa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CounterFact on Multiple Layers"
      ],
      "metadata": {
        "id": "RPi3TvVWyPlg"
      },
      "id": "RPi3TvVWyPlg"
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvlQLatX6yih",
        "outputId": "47649b20-f09a-4c6f-8b87-cf4d3722a125"
      },
      "id": "qvlQLatX6yih",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hplD6SQ6zI6",
        "outputId": "d6b4c207-fde3-4b6b-a098-4f36845ef31f"
      },
      "id": "4hplD6SQ6zI6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2022-09-11 05:01:41--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2022-09-11 05:01:41--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 67.6M 1s\n",
            "    50K .......... .......... .......... .......... ..........  0% 7.97M 4s\n",
            "   100K .......... .......... .......... .......... ..........  0% 9.38M 5s\n",
            "   150K .......... .......... .......... .......... ..........  0% 83.3M 4s\n",
            "   200K .......... .......... .......... .......... ..........  0%  148M 3s\n",
            "   250K .......... .......... .......... .......... ..........  0%  257M 2s\n",
            "   300K .......... .......... .......... .......... ..........  0% 9.77M 3s\n",
            "   350K .......... .......... .......... .......... ..........  0%  177M 3s\n",
            "   400K .......... .......... .......... .......... ..........  0%  178M 2s\n",
            "   450K .......... .......... .......... .......... ..........  0%  151M 2s\n",
            "   500K .......... .......... .......... .......... ..........  0%  124M 2s\n",
            "   550K .......... .......... .......... .......... ..........  1%  135M 2s\n",
            "   600K .......... .......... .......... .......... ..........  1%  167M 2s\n",
            "   650K .......... .......... .......... .......... ..........  1% 20.2M 2s\n",
            "   700K .......... .......... .......... .......... ..........  1%  189M 2s\n",
            "   750K .......... .......... .......... .......... ..........  1%  102M 2s\n",
            "   800K .......... .......... .......... .......... ..........  1% 72.9M 2s\n",
            "   850K .......... .......... .......... .......... ..........  1%  218M 2s\n",
            "   900K .......... .......... .......... .......... ..........  1% 12.6M 2s\n",
            "   950K .......... .......... .......... .......... ..........  1%  180M 2s\n",
            "  1000K .......... .......... .......... .......... ..........  1%  196M 2s\n",
            "  1050K .......... .......... .......... .......... ..........  1%  193M 1s\n",
            "  1100K .......... .......... .......... .......... ..........  2%  178M 1s\n",
            "  1150K .......... .......... .......... .......... ..........  2%  129M 1s\n",
            "  1200K .......... .......... .......... .......... ..........  2%  144M 1s\n",
            "  1250K .......... .......... .......... .......... ..........  2%  153M 1s\n",
            "  1300K .......... .......... .......... .......... ..........  2%  198M 1s\n",
            "  1350K .......... .......... .......... .......... ..........  2%  185M 1s\n",
            "  1400K .......... .......... .......... .......... ..........  2%  249M 1s\n",
            "  1450K .......... .......... .......... .......... ..........  2%  113M 1s\n",
            "  1500K .......... .......... .......... .......... ..........  2%  257M 1s\n",
            "  1550K .......... .......... .......... .......... ..........  2%  198M 1s\n",
            "  1600K .......... .......... .......... .......... ..........  2%  198M 1s\n",
            "  1650K .......... .......... .......... .......... ..........  2%  216M 1s\n",
            "  1700K .......... .......... .......... .......... ..........  3%  236M 1s\n",
            "  1750K .......... .......... .......... .......... ..........  3%  200M 1s\n",
            "  1800K .......... .......... .......... .......... ..........  3%  264M 1s\n",
            "  1850K .......... .......... .......... .......... ..........  3%  282M 1s\n",
            "  1900K .......... .......... .......... .......... ..........  3% 42.1M 1s\n",
            "  1950K .......... .......... .......... .......... ..........  3%  156M 1s\n",
            "  2000K .......... .......... .......... .......... ..........  3%  213M 1s\n",
            "  2050K .......... .......... .......... .......... ..........  3%  242M 1s\n",
            "  2100K .......... .......... .......... .......... ..........  3%  271M 1s\n",
            "  2150K .......... .......... .......... .......... ..........  3%  186M 1s\n",
            "  2200K .......... .......... .......... .......... ..........  3%  215M 1s\n",
            "  2250K .......... .......... .......... .......... ..........  4%  242M 1s\n",
            "  2300K .......... .......... .......... .......... ..........  4%  228M 1s\n",
            "  2350K .......... .......... .......... .......... ..........  4%  142M 1s\n",
            "  2400K .......... .......... .......... .......... ..........  4%  194M 1s\n",
            "  2450K .......... .......... .......... .......... ..........  4%  202M 1s\n",
            "  2500K .......... .......... .......... .......... ..........  4%  198M 1s\n",
            "  2550K .......... .......... .......... .......... ..........  4%  168M 1s\n",
            "  2600K .......... .......... .......... .......... ..........  4%  265M 1s\n",
            "  2650K .......... .......... .......... .......... ..........  4%  237M 1s\n",
            "  2700K .......... .......... .......... .......... ..........  4%  246M 1s\n",
            "  2750K .......... .......... .......... .......... ..........  4% 28.0M 1s\n",
            "  2800K .......... .......... .......... .......... ..........  4%  216M 1s\n",
            "  2850K .......... .......... .......... .......... ..........  5%  217M 1s\n",
            "  2900K .......... .......... .......... .......... ..........  5%  205M 1s\n",
            "  2950K .......... .......... .......... .......... ..........  5%  118M 1s\n",
            "  3000K .......... .......... .......... .......... ..........  5%  184M 1s\n",
            "  3050K .......... .......... .......... .......... ..........  5%  190M 1s\n",
            "  3100K .......... .......... .......... .......... ..........  5%  223M 1s\n",
            "  3150K .......... .......... .......... .......... ..........  5%  159M 1s\n",
            "  3200K .......... .......... .......... .......... ..........  5%  212M 1s\n",
            "  3250K .......... .......... .......... .......... ..........  5%  165M 1s\n",
            "  3300K .......... .......... .......... .......... ..........  5%  235M 1s\n",
            "  3350K .......... .......... .......... .......... ..........  5%  222M 1s\n",
            "  3400K .......... .......... .......... .......... ..........  6%  220M 1s\n",
            "  3450K .......... .......... .......... .......... ..........  6%  190M 1s\n",
            "  3500K .......... .......... .......... .......... ..........  6%  190M 1s\n",
            "  3550K .......... .......... .......... .......... ..........  6%  230M 1s\n",
            "  3600K .......... .......... .......... .......... ..........  6%  281M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6%  285M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6%  177M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6%  179M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6%  219M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6%  212M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6%  214M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7%  180M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7%  250M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7%  272M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7%  266M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7%  200M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7%  248M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7%  252M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7%  282M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7% 16.6M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7%  215M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7%  169M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7%  213M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8%  175M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8%  228M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8%  218M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8%  274M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8%  217M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8%  252M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8%  230M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8% 10.2M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8%  150M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8%  265M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8%  289M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9% 6.19M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9%  152M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9%  215M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9%  203M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9%  277M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9%  197M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9%  208M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9%  192M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9%  226M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9%  179M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9%  228M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9% 7.45M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10%  211M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10%  222M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10%  243M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10%  161M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10%  222M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10%  160M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10%  243M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10%  245M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10%  266M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10%  167M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10%  180M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11%  236M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11%  277M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11%  235M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11% 21.1M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11%  236M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11%  184M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11%  193M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11%  219M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11%  264M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11%  184M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11%  168M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11%  233M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12%  254M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12%  169M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12%  195M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12%  213M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12%  239M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12%  167M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12%  192M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12%  210M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12%  206M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12%  213M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12%  191M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13%  201M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13%  187M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13%  186M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13%  200M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13%  216M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13%  240M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13%  233M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13%  228M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13%  250M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13%  262M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13%  248M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14%  210M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14%  256M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14%  211M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14%  233M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14%  195M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14%  266M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14%  276M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14%  276M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14%  214M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14%  279M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14%  165M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14%  210M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 15%  181M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 15%  230M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 15%  239M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 15%  276M 0s\n",
            "  8750K .......... .......... .......... .......... .......... 15%  211M 0s\n",
            "  8800K .......... .......... .......... .......... .......... 15%  284M 0s\n",
            "  8850K .......... .......... .......... .......... .......... 15%  280M 0s\n",
            "  8900K .......... .......... .......... .......... .......... 15%  279M 0s\n",
            "  8950K .......... .......... .......... .......... .......... 15%  205M 0s\n",
            "  9000K .......... .......... .......... .......... .......... 15% 16.8M 1s\n",
            "  9050K .......... .......... .......... .......... .......... 15%  218M 0s\n",
            "  9100K .......... .......... .......... .......... .......... 16%  185M 0s\n",
            "  9150K .......... .......... .......... .......... .......... 16%  225M 0s\n",
            "  9200K .......... .......... .......... .......... .......... 16%  258M 0s\n",
            "  9250K .......... .......... .......... .......... .......... 16%  264M 0s\n",
            "  9300K .......... .......... .......... .......... .......... 16%  277M 0s\n",
            "  9350K .......... .......... .......... .......... .......... 16% 61.5M 0s\n",
            "  9400K .......... .......... .......... .......... .......... 16%  183M 0s\n",
            "  9450K .......... .......... .......... .......... .......... 16%  192M 0s\n",
            "  9500K .......... .......... .......... .......... .......... 16%  251M 0s\n",
            "  9550K .......... .......... .......... .......... .......... 16%  236M 0s\n",
            "  9600K .......... .......... .......... .......... .......... 16%  270M 0s\n",
            "  9650K .......... .......... .......... .......... .......... 16%  223M 0s\n",
            "  9700K .......... .......... .......... .......... .......... 17%  278M 0s\n",
            "  9750K .......... .......... .......... .......... .......... 17%  109M 0s\n",
            "  9800K .......... .......... .......... .......... .......... 17%  153M 0s\n",
            "  9850K .......... .......... .......... .......... .......... 17% 37.2M 0s\n",
            "  9900K .......... .......... .......... .......... .......... 17%  137M 0s\n",
            "  9950K .......... .......... .......... .......... .......... 17% 24.1M 0s\n",
            " 10000K .......... .......... .......... .......... .......... 17%  147M 0s\n",
            " 10050K .......... .......... .......... .......... .......... 17%  166M 0s\n",
            " 10100K .......... .......... .......... .......... .......... 17% 20.8M 0s\n",
            " 10150K .......... .......... .......... .......... .......... 17%  118M 0s\n",
            " 10200K .......... .......... .......... .......... .......... 17%  169M 0s\n",
            " 10250K .......... .......... .......... .......... .......... 18% 65.5M 0s\n",
            " 10300K .......... .......... .......... .......... .......... 18%  152M 0s\n",
            " 10350K .......... .......... .......... .......... .......... 18% 20.1M 0s\n",
            " 10400K .......... .......... .......... .......... .......... 18%  141M 0s\n",
            " 10450K .......... .......... .......... .......... .......... 18%  155M 0s\n",
            " 10500K .......... .......... .......... .......... .......... 18%  142M 0s\n",
            " 10550K .......... .......... .......... .......... .......... 18%  117M 0s\n",
            " 10600K .......... .......... .......... .......... .......... 18%  141M 0s\n",
            " 10650K .......... .......... .......... .......... .......... 18% 16.5M 0s\n",
            " 10700K .......... .......... .......... .......... .......... 18%  112M 0s\n",
            " 10750K .......... .......... .......... .......... .......... 18%  129M 0s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  150M 0s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  164M 0s\n",
            " 10900K .......... .......... .......... .......... .......... 19%  173M 0s\n",
            " 10950K .......... .......... .......... .......... .......... 19%  141M 0s\n",
            " 11000K .......... .......... .......... .......... .......... 19%  135M 0s\n",
            " 11050K .......... .......... .......... .......... .......... 19%  150M 0s\n",
            " 11100K .......... .......... .......... .......... .......... 19%  161M 0s\n",
            " 11150K .......... .......... .......... .......... .......... 19% 10.2M 1s\n",
            " 11200K .......... .......... .......... .......... .......... 19%  101M 0s\n",
            " 11250K .......... .......... .......... .......... .......... 19%  154M 0s\n",
            " 11300K .......... .......... .......... .......... .......... 19%  154M 0s\n",
            " 11350K .......... .......... .......... .......... .......... 19%  150M 0s\n",
            " 11400K .......... .......... .......... .......... .......... 20%  152M 0s\n",
            " 11450K .......... .......... .......... .......... .......... 20% 14.0M 1s\n",
            " 11500K .......... .......... .......... .......... .......... 20%  143M 1s\n",
            " 11550K .......... .......... .......... .......... .......... 20%  131M 1s\n",
            " 11600K .......... .......... .......... .......... .......... 20%  143M 1s\n",
            " 11650K .......... .......... .......... .......... .......... 20% 19.9M 1s\n",
            " 11700K .......... .......... .......... .......... .......... 20%  125M 1s\n",
            " 11750K .......... .......... .......... .......... .......... 20%  137M 1s\n",
            " 11800K .......... .......... .......... .......... .......... 20%  166M 1s\n",
            " 11850K .......... .......... .......... .......... .......... 20%  174M 1s\n",
            " 11900K .......... .......... .......... .......... .......... 20% 17.7M 1s\n",
            " 11950K .......... .......... .......... .......... .......... 21%  124M 1s\n",
            " 12000K .......... .......... .......... .......... .......... 21%  169M 1s\n",
            " 12050K .......... .......... .......... .......... .......... 21%  170M 1s\n",
            " 12100K .......... .......... .......... .......... .......... 21%  179M 1s\n",
            " 12150K .......... .......... .......... .......... .......... 21%  148M 1s\n",
            " 12200K .......... .......... .......... .......... .......... 21%  159M 1s\n",
            " 12250K .......... .......... .......... .......... .......... 21%  163M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 21% 39.1M 1s\n",
            " 12350K .......... .......... .......... .......... .......... 21%  149M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 21%  182M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 21%  153M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 21% 19.2M 1s\n",
            " 12550K .......... .......... .......... .......... .......... 22%  135M 1s\n",
            " 12600K .......... .......... .......... .......... .......... 22%  145M 1s\n",
            " 12650K .......... .......... .......... .......... .......... 22% 44.2M 1s\n",
            " 12700K .......... .......... .......... .......... .......... 22%  151M 1s\n",
            " 12750K .......... .......... .......... .......... .......... 22%  158M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 22%  165M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 22% 51.1M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 22% 66.1M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 22% 74.5M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 22% 86.2M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 22% 61.6M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 23%  158M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 23%  194M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 23%  236M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 23%  190M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 23%  148M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 23% 91.9M 0s\n",
            " 13400K .......... .......... .......... .......... .......... 23% 90.6M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 23%  181M 0s\n",
            " 13500K .......... .......... .......... .......... .......... 23%  161M 0s\n",
            " 13550K .......... .......... .......... .......... .......... 23%  130M 0s\n",
            " 13600K .......... .......... .......... .......... .......... 23%  210M 0s\n",
            " 13650K .......... .......... .......... .......... .......... 23%  283M 0s\n",
            " 13700K .......... .......... .......... .......... .......... 24%  170M 0s\n",
            " 13750K .......... .......... .......... .......... .......... 24%  163M 0s\n",
            " 13800K .......... .......... .......... .......... .......... 24%  187M 0s\n",
            " 13850K .......... .......... .......... .......... .......... 24%  184M 0s\n",
            " 13900K .......... .......... .......... .......... .......... 24%  142M 0s\n",
            " 13950K .......... .......... .......... .......... .......... 24%  180M 0s\n",
            " 14000K .......... .......... .......... .......... .......... 24%  214M 0s\n",
            " 14050K .......... .......... .......... .......... .......... 24%  170M 0s\n",
            " 14100K .......... .......... .......... .......... .......... 24%  223M 0s\n",
            " 14150K .......... .......... .......... .......... .......... 24%  214M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 24%  255M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 25%  286M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 25%  237M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 25%  224M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 25%  279M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 25%  257M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 25%  265M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 25%  195M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 25%  265M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 25%  237M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 25%  233M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 25%  217M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 26%  241M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 26%  276M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 26%  258M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 26%  236M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 26%  245M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 26% 14.4M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 26%  149M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 26%  141M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 26%  241M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 26%  275M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 26%  258M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 26%  210M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 27%  254M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 27%  240M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 27%  277M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 27% 84.7M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 27%  233M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 27%  175M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 27%  145M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 27% 70.7M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 27% 64.5M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 27%  101M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 27% 86.2M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 28% 77.2M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 28% 96.2M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 28%  107M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 28% 88.2M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 28% 75.9M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 28%  122M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 28%  130M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 28% 96.6M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 28% 86.4M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 28%  137M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 28%  115M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 28%  109M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 29%  119M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 29%  102M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 29%  145M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 29%  163M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 29%  124M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 29% 95.2M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 29%  135M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 29%  163M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 29%  135M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 29%  165M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 29%  164M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 30%  160M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 30%  147M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 30% 8.27M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 30%  127M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 30%  128M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 30%  121M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 30%  157M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 30%  267M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 30%  165M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 30%  197M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 30%  177M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 30%  272M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 31%  169M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 31%  130M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 31% 10.9M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 31%  124M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 31%  139M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 31%  129M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 31%  152M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 31%  104M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 31%  129M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 31%  164M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 31%  264M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 32%  235M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 32%  283M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 32%  228M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 32%  216M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 32%  288M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 32% 24.7M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 32%  119M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 32%  130M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 32%  186M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 32%  266M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 32%  162M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 33%  190M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 33%  266M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 33%  255M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 33%  244M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 33%  228M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 33%  168M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 33%  123M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 33%  128M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 33%  142M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 33%  120M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 33%  189M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 33%  189M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 34%  241M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 34% 14.3M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 34%  104M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 34%  111M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 34%  272M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 34%  178M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 34%  189M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 34%  224M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 34%  290M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 34%  207M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 34%  195M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 35%  131M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 35%  123M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 35%  188M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 35% 19.7M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 35%  101M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 35%  141M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 35%  168M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 35%  157M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 35%  126M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 35%  150M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 35% 49.0M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 35%  112M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 36%  105M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 36%  139M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 36%  130M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 36%  102M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 36% 99.0M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 36%  126M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 36%  135M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 36%  102M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 36%  111M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 36%  125M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 36%  120M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 37%  104M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 37% 85.8M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 37% 44.3M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 37%  146M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 37% 9.91M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 37% 78.4M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 37%  144M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 37%  166M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 37%  147M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 37%  145M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 37%  180M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 38%  152M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 38% 50.7M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 38% 45.2M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 38%  142M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 38%  152M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 38%  117M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 38%  112M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 38%  143M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 38%  145M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 38%  159M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 38%  150M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 38%  144M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 39%  152M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 39% 15.6M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 39%  111M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 39%  160M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 39%  164M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 39%  147M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 39%  112M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 39%  105M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 39%  145M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 39%  112M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 39%  138M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 40% 12.2M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 40%  148M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 40%  128M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 40%  105M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 40%  174M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 40%  170M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 40%  166M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 40%  143M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 40%  152M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 40%  107M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 40%  179M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 40%  149M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 41%  164M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 41%  151M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 41%  145M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 41%  109M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 41%  147M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 41%  142M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 41%  125M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 41%  161M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 41%  170M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 41%  120M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 41%  154M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 42%  125M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 42% 63.6M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 42% 17.5M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 42%  166M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 42%  114M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 42%  145M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 42%  172M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 42%  142M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 42%  135M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 42%  177M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 42%  151M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 42%  154M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 43%  157M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 43%  164M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 43% 72.6M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 43%  133M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 43%  153M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 43%  156M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 43% 70.1M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 43%  139M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 43%  135M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 43%  137M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 43%  123M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 44%  120M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 44%  129M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 44%  162M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 44%  162M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 44%  136M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 44%  123M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 44%  162M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 44%  174M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 44% 12.9M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 44%  126M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 44%  148M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 45%  169M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 45% 28.2M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 45%  121M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 45%  168M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 45%  131M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 45%  118M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 45% 99.6M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 45%  139M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 45%  183M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 45%  160M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 45%  127M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 45%  134M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 46%  132M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 46%  177M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 46%  150M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 46%  161M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 46%  158M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 46%  139M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 46%  107M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 46%  139M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 46%  150M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 46%  163M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 46% 30.9M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 47%  127M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 47%  150M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 47%  121M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 47%  130M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 47%  168M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 47%  184M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 47%  167M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 47%  150M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 47%  151M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 47%  162M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 47%  183M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 47%  122M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 48% 15.0M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 48%  126M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 48%  117M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 48%  116M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 48%  162M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 48%  161M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 48%  150M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 48%  145M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 48%  181M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 48%  167M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 48%  178M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 49%  136M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 49%  157M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 49% 4.99M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 49%  138M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 49%  109M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 49%  156M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 49%  156M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 49%  162M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 49%  156M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 49%  170M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 49%  172M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 50% 5.67M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 50%  124M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 50%  115M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 50%  150M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 50%  111M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 50%  123M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 50%  139M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 50%  105M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 50%  137M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 50% 98.2M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 50%  142M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 50%  223M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 51%  213M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 51%  198M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 51%  215M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 51%  226M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 51%  195M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 51%  172M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 51%  172M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 51%  237M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 51%  240M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 51%  216M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 51%  258M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 52%  235M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 52%  270M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 52%  187M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 52%  215M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 52%  199M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 52%  228M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 52%  224M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 52%  202M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 52%  277M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 52%  255M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 52%  211M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 52%  237M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 53%  178M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 53%  196M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 53%  186M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 53%  260M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 53%  232M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53%  248M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53%  196M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 53%  274M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 53%  289M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 53%  231M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 53%  217M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 54%  272M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 54%  245M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 54%  245M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 54%  241M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 54%  232M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 54% 48.1M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 54%  202M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 54%  173M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 54%  187M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 54%  188M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 54%  216M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 54%  226M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 55%  234M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 55%  294M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 55%  266M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 55%  224M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 55%  204M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 55%  195M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 55%  272M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55% 77.2M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55% 60.0M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55% 12.4M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55%  116M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56%  167M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56%  171M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56%  156M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56% 48.4M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56%  156M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56% 99.5M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56%  137M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56%  216M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56%  166M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56%  193M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56%  211M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57%  160M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57% 52.3M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57%  123M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57%  120M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57%  123M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57%  100M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57% 22.5M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57%  216M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57%  196M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57%  192M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57%  240M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57% 18.4M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58%  198M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58%  195M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58%  227M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58%  183M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58%  285M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58%  212M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58%  260M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58%  260M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58%  288M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58% 10.4M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58%  167M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59%  217M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59%  291M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59%  260M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59%  264M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59%  273M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59%  120M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59%  171M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59%  187M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59%  206M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59%  208M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59%  260M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59%  213M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60%  199M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60%  245M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60%  177M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60%  260M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60%  243M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60% 44.4M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60%  202M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60% 65.1M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60%  261M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60% 13.9M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60%  156M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61%  199M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61%  267M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61%  254M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61%  152M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61%  267M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61%  264M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61%  214M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61%  226M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61%  221M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61%  250M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61% 66.9M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61%  183M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62%  258M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62% 9.60M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62%  209M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62%  148M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62%  292M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62%  302M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62%  296M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62% 27.2M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62%  191M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62% 81.3M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62%  253M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63% 56.4M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63% 57.8M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63% 5.73M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63%  240M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63% 41.2M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63%  234M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63% 80.6M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63% 87.8M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63% 35.8M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63%  187M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63%  228M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64% 46.1M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64% 96.5M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64% 10.8M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64%  190M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64%  183M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64%  195M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64%  217M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64%  198M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64%  203M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64%  181M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64%  279M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64%  158M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65%  203M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65%  189M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65% 34.4M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65%  250M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65%  209M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65% 55.8M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65% 12.0M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65%  167M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65%  209M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65%  218M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65%  228M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66%  201M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66%  260M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66%  186M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66% 11.8M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66%  154M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66%  191M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66%  201M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66%  234M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66%  241M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  243M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66%  203M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66%  215M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67%  214M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67%  220M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67%  171M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67%  251M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67%  229M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67% 12.5M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67%  177M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67%  251M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67%  293M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67% 28.8M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67%  212M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  248M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68%  199M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68%  176M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68%  185M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68%  237M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68%  216M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  207M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68%  191M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68%  216M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68%  249M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68%  204M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69%  155M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69% 18.1M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69%  184M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69%  258M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69%  225M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69%  249M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69%  274M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69% 59.5M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69%  160M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69%  232M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69%  212M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69%  257M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70% 53.5M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70%  186M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70% 25.2M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70%  157M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70%  194M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70%  213M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70% 40.9M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70%  186M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70%  240M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70%  224M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70% 20.7M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71%  179M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71%  166M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71%  236M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71%  260M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71%  256M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71%  226M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71%  216M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71% 50.5M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71%  200M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71%  111M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71% 33.7M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71%  244M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72%  223M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72% 11.5M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72%  202M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72%  229M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72%  262M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72%  179M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72%  244M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72%  268M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72%  272M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72% 13.4M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72%  177M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73%  188M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73%  177M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73%  159M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73% 27.1M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73%  255M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73%  269M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73% 12.3M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73%  212M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73%  184M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73%  237M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73%  221M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73%  255M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74%  225M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74%  238M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74%  174M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74%  284M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74% 10.1M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74%  223M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74%  194M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74%  185M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74%  214M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74%  279M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74%  252M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75%  282M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75%  240M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75%  270M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75%  135M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75% 58.5M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75%  210M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75% 23.9M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75% 22.5M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75%  201M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75%  197M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75%  213M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76%  187M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76% 22.8M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76%  196M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76%  251M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76%  238M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76% 10.8M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76%  210M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76%  219M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76%  216M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76%  229M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76%  102M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76%  214M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77%  187M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77%  247M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77% 54.5M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77%  208M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77%  184M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77%  196M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77%  177M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77%  215M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77%  238M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77%  280M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77%  197M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78%  205M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78%  234M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78%  260M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78%  210M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78%  187M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78% 44.7M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78%  150M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78%  190M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78%  208M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78%  219M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78% 82.8M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78%  187M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79%  226M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79%  214M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79%  157M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79% 54.3M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79%  136M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79%  131M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79%  178M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79%  221M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79%  283M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79%  162M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79%  234M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80%  231M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80%  259M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80%  240M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80% 18.5M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80%  152M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80%  208M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80%  189M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80%  203M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80%  246M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80%  125M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80%  107M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81% 31.0M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81%  254M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81%  199M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81%  201M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81% 15.0M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81%  221M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81%  229M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81% 30.2M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81%  244M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81%  171M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81%  220M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81%  187M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82%  254M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82%  187M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82%  253M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82%  198M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82%  222M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82%  273M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82% 17.5M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82%  202M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82%  191M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82%  222M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82%  244M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83%  234M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83% 48.9M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83%  186M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83%  229M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83%  222M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83%  223M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83% 24.1M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83%  169M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83%  161M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83%  208M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83%  229M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83%  230M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84%  114M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84%  155M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84%  128M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84%  127M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84% 61.0M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84% 98.3M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84% 90.4M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84%  113M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84% 84.3M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84% 75.2M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84% 88.5M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85% 83.6M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85% 82.4M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85% 76.0M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85% 92.3M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85% 98.3M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85% 80.4M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85%  139M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85%  169M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85% 6.08M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85% 25.9M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85%  175M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85%  125M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86% 12.5M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86% 50.6M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86% 73.3M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86%  104M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86% 93.6M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86% 78.8M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86%  137M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86%  139M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86%  172M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86%  143M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86%  166M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87%  156M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87%  175M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87%  155M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87%  161M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87%  149M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87%  139M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87%  109M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87%  170M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87% 98.8M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87% 93.9M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87% 69.7M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88%  177M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88%  183M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88%  161M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88%  131M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88%  168M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88%  156M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88%  160M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88%  149M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88%  165M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88%  149M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88%  153M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88%  148M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89%  164M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89%  165M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89%  142M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89%  111M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89% 44.8M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89% 78.6M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89% 95.1M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89%  148M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89%  169M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89%  167M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89%  159M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90%  126M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90%  156M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90% 8.47M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90%  120M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90%  142M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90%  178M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90% 15.4M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90% 97.3M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90%  218M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90%  235M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90%  130M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90%  133M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91%  196M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91%  251M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91%  256M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91%  247M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91%  193M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91%  226M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91%  202M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91%  274M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91% 8.15M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91%  162M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91%  268M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92%  271M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92%  245M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92% 9.86M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92%  228M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92%  245M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92%  236M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92% 17.5M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92%  246M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92%  234M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92% 88.7M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92%  152M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92%  150M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93%  164M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93%  140M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93% 23.7M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93% 67.8M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93%  173M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93% 68.0M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93% 91.3M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93% 72.1M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93%  167M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93% 63.4M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93% 70.6M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94% 99.9M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94%  170M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94%  146M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94%  173M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94%  164M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94%  172M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94%  150M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94%  111M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94%  143M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94%  169M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94%  162M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95%  157M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95%  145M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95% 83.5M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95%  140M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95%  172M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95%  147M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95%  159M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95%  163M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95%  184M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95%  161M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95%  140M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95%  147M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96%  166M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96%  155M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96%  106M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96% 68.9M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96%  165M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96%  159M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96%  160M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96%  133M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96%  147M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96%  171M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96%  188M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97%  132M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97%  144M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97%  188M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97%  168M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97% 94.5M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97%  100M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97% 95.2M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97%  174M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97%  131M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97%  121M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97%  141M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97%  185M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98%  134M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98%  160M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98%  155M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98%  126M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98% 93.9M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98% 94.2M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98%  115M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98%  103M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98% 89.6M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98%  171M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98%  187M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99%  183M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99%  121M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99%  159M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99%  178M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99%  151M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99%  131M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99%  120M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99%  159M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99%  175M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99%  147M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99%  155M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100% 40.4M=0.6s\n",
            "\n",
            "2022-09-11 05:01:42 (88.7 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.7 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqYpRqhn7UPk",
        "outputId": "ba36600d-fc6e-4699-9b40-e746c5a481df"
      },
      "id": "ZqYpRqhn7UPk",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.7\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         6.1 MB\n",
            "    ca-certificates-2022.07.19 |       h06a4308_0         131 KB\n",
            "    urllib3-1.26.11            |   py37h06a4308_0         178 KB\n",
            "    python-3.7.13              |       h12debd9_0        53.5 MB\n",
            "    pip-22.1.2                 |   py37h06a4308_0         2.9 MB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    setuptools-63.4.1          |   py37h06a4308_0         1.4 MB\n",
            "    pycparser-2.21             |     pyhd3eb1b0_0          94 KB\n",
            "    requests-2.28.1            |   py37h06a4308_0          91 KB\n",
            "    conda-package-handling-1.8.1|   py37h7f8727e_0         954 KB\n",
            "    pyopenssl-22.0.0           |     pyhd3eb1b0_0          49 KB\n",
            "    cytoolz-0.11.0             |   py37h7b6447c_0         367 KB\n",
            "    ruamel_yaml-0.15.100       |   py37h27cfd23_0         267 KB\n",
            "    xz-5.2.5                   |       h7f8727e_1         389 KB\n",
            "    zlib-1.2.12                |       h5eee18b_3         124 KB\n",
            "    ncurses-6.3                |       h5eee18b_3         1.1 MB\n",
            "    cryptography-37.0.1        |   py37h9ce1e76_0         1.5 MB\n",
            "    pycosat-0.6.3              |   py37h27cfd23_0         108 KB\n",
            "    cffi-1.15.1                |   py37h74dc2b5_0         228 KB\n",
            "    tk-8.6.12                  |       h1ccaba5_0         3.3 MB\n",
            "    idna-3.3                   |     pyhd3eb1b0_0          55 KB\n",
            "    pysocks-1.7.1              |           py37_1          27 KB\n",
            "    charset-normalizer-2.0.4   |     pyhd3eb1b0_0          33 KB\n",
            "    openssl-1.1.1q             |       h7f8727e_0         3.8 MB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         8.5 MB\n",
            "    tqdm-4.64.0                |   py37h06a4308_0         121 KB\n",
            "    brotlipy-0.7.0             |py37h27cfd23_1003         350 KB\n",
            "    conda-4.14.0               |   py37h06a4308_0        1007 KB\n",
            "    ld_impl_linux-64-2.38      |       h1181459_1         732 KB\n",
            "    certifi-2022.6.15          |   py37h06a4308_0         156 KB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    readline-8.1.2             |       h7f8727e_1         423 KB\n",
            "    toolz-0.11.2               |     pyhd3eb1b0_0          48 KB\n",
            "    wheel-0.37.1               |     pyhd3eb1b0_0          31 KB\n",
            "    sqlite-3.39.2              |       h5082296_0         1.5 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        89.5 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    brotlipy:               0.7.0-py37h27cfd23_1003\n",
            "    charset-normalizer:     2.0.4-pyhd3eb1b0_0     \n",
            "    conda-package-handling: 1.8.1-py37h7f8727e_0   \n",
            "    cytoolz:                0.11.0-py37h7b6447c_0  \n",
            "    ld_impl_linux-64:       2.38-h1181459_1        \n",
            "    toolz:                  0.11.2-pyhd3eb1b0_0    \n",
            "    tqdm:                   4.64.0-py37h06a4308_0  \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2022.07.19-h06a4308_0   \n",
            "    certifi:                2018.4.16-py36_0        --> 2022.6.15-py37h06a4308_0\n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.15.1-py37h74dc2b5_0   \n",
            "    conda:                  4.5.4-py36_0            --> 4.14.0-py37h06a4308_0   \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 37.0.1-py37h9ce1e76_0   \n",
            "    idna:                   2.6-py36h82fb2a8_1      --> 3.3-pyhd3eb1b0_0        \n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 11.2.0-h1234567_1       \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 11.2.0-h1234567_1       \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.3-h5eee18b_3          \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1q-h7f8727e_0       \n",
            "    pip:                    10.0.1-py36_0           --> 22.1.2-py37h06a4308_0   \n",
            "    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py37h27cfd23_0    \n",
            "    pycparser:              2.18-py36hf9f622e_1     --> 2.21-pyhd3eb1b0_0       \n",
            "    pyopenssl:              18.0.0-py36_0           --> 22.0.0-pyhd3eb1b0_0     \n",
            "    pysocks:                1.6.8-py36_0            --> 1.7.1-py37_1            \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.7.13-h12debd9_0       \n",
            "    readline:               7.0-ha6073c6_4          --> 8.1.2-h7f8727e_1        \n",
            "    requests:               2.18.4-py36he2e5f8d_1   --> 2.28.1-py37h06a4308_0   \n",
            "    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.100-py37h27cfd23_0 \n",
            "    setuptools:             39.2.0-py36_0           --> 63.4.1-py37h06a4308_0   \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.39.2-h5082296_0       \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.12-h1ccaba5_0       \n",
            "    urllib3:                1.22-py36hbe7ace6_0     --> 1.26.11-py37h06a4308_0  \n",
            "    wheel:                  0.31.1-py36_0           --> 0.37.1-pyhd3eb1b0_0     \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7f8727e_1        \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0        \n",
            "    zlib:                   1.2.11-ha838bed_2       --> 1.2.12-h5eee18b_3       \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         498 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\r_openmp_mutex-5.1    | 21 KB     |            |   0% \r_openmp_mutex-5.1    | 21 KB     | ########## | 100% \r_openmp_mutex-5.1    | 21 KB     | ########## | 100% \n",
            "\rlibgomp-11.2.0       | 474 KB    |            |   0% \rlibgomp-11.2.0       | 474 KB    | ########## | 100% \n",
            "\r_libgcc_mutex-0.1    | 3 KB      |            |   0% \r_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Retrieving notices: ...working... done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rlibstdcxx-ng-11.2.0  |  6.1 MB |            |   0% \rlibstdcxx-ng-11.2.0  |  6.1 MB | #######5   |  76% \rlibstdcxx-ng-11.2.0  |  6.1 MB | #########8 |  99% \rlibstdcxx-ng-11.2.0  |  6.1 MB | ########## | 100% \n",
            "\rca-certificates-2022 |  131 KB |            |   0% \rca-certificates-2022 |  131 KB | ########## | 100% \n",
            "\rurllib3-1.26.11      |  178 KB |            |   0% \rurllib3-1.26.11      |  178 KB | #######9   |  79% \rurllib3-1.26.11      |  178 KB | ########## | 100% \n",
            "\rpython-3.7.13        | 53.5 MB |            |   0% \rpython-3.7.13        | 53.5 MB | #1         |  12% \rpython-3.7.13        | 53.5 MB | ##8        |  29% \rpython-3.7.13        | 53.5 MB | ####3      |  44% \rpython-3.7.13        | 53.5 MB | #####3     |  53% \rpython-3.7.13        | 53.5 MB | ######4    |  65% \rpython-3.7.13        | 53.5 MB | #######4   |  75% \rpython-3.7.13        | 53.5 MB | ########4  |  85% \rpython-3.7.13        | 53.5 MB | #########2 |  92% \rpython-3.7.13        | 53.5 MB | #########7 |  97% \rpython-3.7.13        | 53.5 MB | ########## | 100% \n",
            "\rpip-22.1.2           |  2.9 MB |            |   0% \rpip-22.1.2           |  2.9 MB | #######6   |  77% \rpip-22.1.2           |  2.9 MB | ########9  |  90% \rpip-22.1.2           |  2.9 MB | ########## | 100% \n",
            "\rlibffi-3.3           |   54 KB |            |   0% \rlibffi-3.3           |   54 KB | ########## | 100% \n",
            "\rsetuptools-63.4.1    |  1.4 MB |            |   0% \rsetuptools-63.4.1    |  1.4 MB | #######8   |  79% \rsetuptools-63.4.1    |  1.4 MB | #########6 |  96% \rsetuptools-63.4.1    |  1.4 MB | ########## | 100% \n",
            "\rpycparser-2.21       |   94 KB |            |   0% \rpycparser-2.21       |   94 KB | ########## | 100% \n",
            "\rrequests-2.28.1      |   91 KB |            |   0% \rrequests-2.28.1      |   91 KB | ########## | 100% \n",
            "\rconda-package-handli |  954 KB |            |   0% \rconda-package-handli |  954 KB | ########5  |  85% \rconda-package-handli |  954 KB | ########## | 100% \n",
            "\rpyopenssl-22.0.0     |   49 KB |            |   0% \rpyopenssl-22.0.0     |   49 KB | ########## | 100% \n",
            "\rcytoolz-0.11.0       |  367 KB |            |   0% \rcytoolz-0.11.0       |  367 KB | ########## | 100% \n",
            "\rruamel_yaml-0.15.100 |  267 KB |            |   0% \rruamel_yaml-0.15.100 |  267 KB | 4          |   4% \rruamel_yaml-0.15.100 |  267 KB | ########## | 100% \n",
            "\rxz-5.2.5             |  389 KB |            |   0% \rxz-5.2.5             |  389 KB | #########  |  91% \rxz-5.2.5             |  389 KB | ########## | 100% \n",
            "\rzlib-1.2.12          |  124 KB |            |   0% \rzlib-1.2.12          |  124 KB | ########## | 100% \n",
            "\rncurses-6.3          |  1.1 MB |            |   0% \rncurses-6.3          |  1.1 MB | #######8   |  79% \rncurses-6.3          |  1.1 MB | #########7 |  97% \rncurses-6.3          |  1.1 MB | ########## | 100% \n",
            "\rcryptography-37.0.1  |  1.5 MB |            |   0% \rcryptography-37.0.1  |  1.5 MB |            |   1% \rcryptography-37.0.1  |  1.5 MB | ########1  |  82% \rcryptography-37.0.1  |  1.5 MB | ########## | 100% \n",
            "\rpycosat-0.6.3        |  108 KB |            |   0% \rpycosat-0.6.3        |  108 KB | #########1 |  92% \rpycosat-0.6.3        |  108 KB | ########## | 100% \n",
            "\rcffi-1.15.1          |  228 KB |            |   0% \rcffi-1.15.1          |  228 KB | #5         |  16% \rcffi-1.15.1          |  228 KB | ########## | 100% \n",
            "\rtk-8.6.12            |  3.3 MB |            |   0% \rtk-8.6.12            |  3.3 MB | #######6   |  77% \rtk-8.6.12            |  3.3 MB | #########4 |  94% \rtk-8.6.12            |  3.3 MB | ########## | 100% \n",
            "\ridna-3.3             |   55 KB |            |   0% \ridna-3.3             |   55 KB | ########## | 100% \n",
            "\rpysocks-1.7.1        |   27 KB |            |   0% \rpysocks-1.7.1        |   27 KB | ########## | 100% \n",
            "\rcharset-normalizer-2 |   33 KB |            |   0% \rcharset-normalizer-2 |   33 KB | ########## | 100% \n",
            "\ropenssl-1.1.1q       |  3.8 MB |            |   0% \ropenssl-1.1.1q       |  3.8 MB | #######7   |  77% \ropenssl-1.1.1q       |  3.8 MB | #########7 |  97% \ropenssl-1.1.1q       |  3.8 MB | ########## | 100% \n",
            "\rlibgcc-ng-11.2.0     |  8.5 MB |            |   0% \rlibgcc-ng-11.2.0     |  8.5 MB | #######5   |  75% \rlibgcc-ng-11.2.0     |  8.5 MB | #########8 |  98% \rlibgcc-ng-11.2.0     |  8.5 MB | ########## | 100% \n",
            "\rtqdm-4.64.0          |  121 KB |            |   0% \rtqdm-4.64.0          |  121 KB | ########## | 100% \n",
            "\rbrotlipy-0.7.0       |  350 KB |            |   0% \rbrotlipy-0.7.0       |  350 KB | 3          |   3% \rbrotlipy-0.7.0       |  350 KB | ########## | 100% \n",
            "\rconda-4.14.0         | 1007 KB |            |   0% \rconda-4.14.0         | 1007 KB | ########2  |  82% \rconda-4.14.0         | 1007 KB | #########9 |  99% \rconda-4.14.0         | 1007 KB | ########## | 100% \n",
            "\rld_impl_linux-64-2.3 |  732 KB |            |   0% \rld_impl_linux-64-2.3 |  732 KB | ########7  |  88% \rld_impl_linux-64-2.3 |  732 KB | ########## | 100% \n",
            "\rcertifi-2022.6.15    |  156 KB |            |   0% \rcertifi-2022.6.15    |  156 KB | ########## | 100% \n",
            "\ryaml-0.2.5           |   87 KB |            |   0% \ryaml-0.2.5           |   87 KB | ########## | 100% \n",
            "\rreadline-8.1.2       |  423 KB |            |   0% \rreadline-8.1.2       |  423 KB | ########## | 100% \n",
            "\rtoolz-0.11.2         |   48 KB |            |   0% \rtoolz-0.11.2         |   48 KB | ########## | 100% \n",
            "\rwheel-0.37.1         |   31 KB |            |   0% \rwheel-0.37.1         |   31 KB | ########## | 100% \n",
            "\rsqlite-3.39.2        |  1.5 MB |            |   0% \rsqlite-3.39.2        |  1.5 MB | ########1  |  82% \rsqlite-3.39.2        |  1.5 MB | ########## | 100% \n",
            "\n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\n",
            "\n",
            "  - defaults/linux-64::brotlipy==0.7.0=py37h27cfd23_1003\n",
            "  - defaults/linux-64::conda==4.14.0=py37h06a4308_0\n",
            "  - defaults/linux-64::python==3.7.13=h12debd9_0\n",
            "  - defaults/noarch::idna==3.3=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::readline==8.1.2=h7f8727e_1\n",
            "  - defaults/linux-64::libedit==3.1.20170329=h6b74fdf_2\n",
            "  - defaults/linux-64::cffi==1.15.1=py37h74dc2b5_0\n",
            "  - defaults/linux-64::zlib==1.2.12=h5eee18b_3\n",
            "  - defaults/linux-64::certifi==2022.6.15=py37h06a4308_0\n",
            "  - defaults/linux-64::tk==8.6.12=h1ccaba5_0\n",
            "  - defaults/linux-64::xz==5.2.5=h7f8727e_1\n",
            "  - defaults/noarch::wheel==0.37.1=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::pycosat==0.6.3=py37h27cfd23_0\n",
            "  - defaults/linux-64::yaml==0.2.5=h7b6447c_0\n",
            "  - defaults/linux-64::openssl==1.1.1q=h7f8727e_0\n",
            "  - defaults/linux-64::urllib3==1.26.11=py37h06a4308_0\n",
            "  - defaults/linux-64::conda-package-handling==1.8.1=py37h7f8727e_0\n",
            "  - defaults/linux-64::pysocks==1.7.1=py37_1\n",
            "  - defaults/linux-64::sqlite==3.39.2=h5082296_0\n",
            "  - defaults/linux-64::cytoolz==0.11.0=py37h7b6447c_0\n",
            "  - defaults/linux-64::chardet==3.0.4=py36h0f667ec_1\n",
            "  - defaults/noarch::toolz==0.11.2=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::ruamel_yaml==0.15.100=py37h27cfd23_0\n",
            "  - defaults/linux-64::setuptools==63.4.1=py37h06a4308_0\n",
            "  - defaults/noarch::charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::requests==2.28.1=py37h06a4308_0\n",
            "  - defaults/linux-64::ncurses==6.3=h5eee18b_3\n",
            "  - defaults/linux-64::libgcc-ng==11.2.0=h1234567_1\n",
            "  - defaults/noarch::pyopenssl==22.0.0=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::tqdm==4.64.0=py37h06a4308_0\n",
            "  - defaults/linux-64::six==1.11.0=py36h372c433_1\n",
            "  - defaults/linux-64::asn1crypto==0.24.0=py36_0\n",
            "  - defaults/linux-64::pip==22.1.2=py37h06a4308_0\n",
            "  - defaults/linux-64::libffi==3.3=he6710b0_2\n",
            "  - defaults/noarch::pycparser==2.21=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::cryptography==37.0.1=py37h9ce1e76_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--l1R1mF7F2h",
        "outputId": "4dc5b5d1-94a5-4cce-8a58-4d700325bde7"
      },
      "id": "--l1R1mF7F2h",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
      ],
      "metadata": {
        "id": "nYzkEfK-7czj"
      },
      "id": "nYzkEfK-7czj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('rome')"
      ],
      "metadata": {
        "id": "ssbjOM-WCRJ3"
      },
      "id": "ssbjOM-WCRJ3",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./scripts/setup_conda.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T41-0dgCF5J",
        "outputId": "8969455c-03fb-4874-f474-ad463e265abc"
      },
      "id": "5T41-0dgCF5J",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Linux\n",
            "Creating conda environment rome\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pytorch-1.10.2       | 1.21 GB   | : 100% 1.0/1 [03:09<00:00, 189.62s/it]              \n",
            "intel-openmp-2022.1. | 4.5 MB    | : 100% 1.0/1 [00:00<00:00,  3.77it/s]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | : 100% 1.0/1 [00:15<00:00, 15.26s/it]               \n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00,  9.08it/s]\n",
            "mkl-2022.1.0         | 129.7 MB  | : 100% 1.0/1 [00:04<00:00,  4.70s/it]               \n",
            "pip-21.2.4           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  4.46it/s]\n",
            "python-3.9.7         | 18.6 MB   | : 100% 1.0/1 [00:01<00:00,  1.23s/it]\n",
            "typing_extensions-4. | 42 KB     | : 100% 1.0/1 [00:00<00:00, 16.47it/s]\n",
            "setuptools-63.4.1    | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  7.43it/s]\n",
            "tzdata-2022a         | 109 KB    | : 100% 1.0/1 [00:00<00:00,  8.40it/s]\n",
            "pytorch-mutex-1.0    | 3 KB      | : 100% 1.0/1 [00:00<00:00, 13.88it/s]\n",
            "certifi-2022.6.15    | 153 KB    | : 100% 1.0/1 [00:00<00:00, 13.34it/s]\n",
            "libuv-1.40.0         | 736 KB    | : 100% 1.0/1 [00:00<00:00, 11.45it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Installing pip dependencies: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/rome/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/rome/scripts/condaenv.oy889v8l.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "Collecting aiosignal==1.2.0\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting allennlp==2.9.0\n",
            "  Downloading allennlp-2.9.0-py3-none-any.whl (716 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "Collecting argon2-cffi==21.3.0\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Collecting argon2-cffi-bindings==21.2.0\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "Collecting asttokens==2.0.5\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Collecting async-timeout==4.0.2\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting attrs==21.4.0\n",
            "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
            "Collecting backcall==0.2.0\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting backports-csv==1.0.7\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting base58==2.1.1\n",
            "  Using cached base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting beautifulsoup4==4.10.0\n",
            "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
            "Collecting black==22.1.0\n",
            "  Downloading black-22.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "Collecting bleach==4.1.0\n",
            "  Downloading bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n",
            "Collecting blis==0.7.5\n",
            "  Downloading blis-0.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "Collecting boto3==1.20.47\n",
            "  Downloading boto3-1.20.47-py3-none-any.whl (131 kB)\n",
            "Collecting botocore==1.23.47\n",
            "  Downloading botocore-1.23.47-py3-none-any.whl (8.5 MB)\n",
            "Collecting cached-path==1.0.2\n",
            "  Downloading cached_path-1.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting cachetools==5.0.0\n",
            "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
            "Collecting catalogue==2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Collecting cffi==1.15.0\n",
            "  Downloading cffi-1.15.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (444 kB)\n",
            "Collecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "Collecting charset-normalizer==2.0.11\n",
            "  Downloading charset_normalizer-2.0.11-py3-none-any.whl (39 kB)\n",
            "Collecting checklist==0.0.11\n",
            "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
            "Collecting cheroot==8.6.0\n",
            "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
            "Collecting cherrypy==18.6.1\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "Collecting click==8.0.3\n",
            "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
            "Collecting cryptography==36.0.1\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "Collecting cymem==2.0.6\n",
            "  Downloading cymem-2.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
            "Collecting datasets==1.18.3\n",
            "  Using cached datasets-1.18.3-py3-none-any.whl (311 kB)\n",
            "Collecting debugpy==1.5.1\n",
            "  Downloading debugpy-1.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "Collecting decorator==5.1.1\n",
            "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting defusedxml==0.7.1\n",
            "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting dill==0.3.4\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "Collecting docker-pycreds==0.4.0\n",
            "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting einops==0.4.0\n",
            "  Downloading einops-0.4.0-py3-none-any.whl (28 kB)\n",
            "Collecting entrypoints==0.4\n",
            "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting executing==0.8.2\n",
            "  Downloading executing-0.8.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting fairscale==0.4.5\n",
            "  Downloading fairscale-0.4.5.tar.gz (240 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Collecting feedparser==6.0.8\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "Collecting filelock==3.4.2\n",
            "  Downloading filelock-3.4.2-py3-none-any.whl (9.9 kB)\n",
            "Collecting frozenlist==1.3.0\n",
            "  Downloading frozenlist-1.3.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
            "Collecting fsspec==2022.1.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "Collecting future==0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "Collecting gitdb==4.0.9\n",
            "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "Collecting gitpython==3.1.26\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "Collecting google-api-core==2.5.0\n",
            "  Downloading google_api_core-2.5.0-py2.py3-none-any.whl (111 kB)\n",
            "Collecting google-auth==2.6.0\n",
            "  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
            "Collecting google-cloud-core==2.2.2\n",
            "  Downloading google_cloud_core-2.2.2-py2.py3-none-any.whl (29 kB)\n",
            "Collecting google-cloud-storage==1.44.0\n",
            "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
            "Collecting google-crc32c==1.3.0\n",
            "  Downloading google_crc32c-1.3.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (36 kB)\n",
            "Collecting google-resumable-media==2.1.0\n",
            "  Downloading google_resumable_media-2.1.0-py2.py3-none-any.whl (75 kB)\n",
            "Collecting googleapis-common-protos==1.54.0\n",
            "  Downloading googleapis_common_protos-1.54.0-py2.py3-none-any.whl (207 kB)\n",
            "Collecting h5py==3.6.0\n",
            "  Downloading h5py-3.6.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "Collecting higher==0.2.1\n",
            "  Using cached higher-0.2.1-py3-none-any.whl (27 kB)\n",
            "Collecting huggingface-hub==0.2.1\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "Collecting hydra-core==1.1.1\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "Collecting idna==3.3\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "Collecting iniconfig==1.1.1\n",
            "  Using cached iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Collecting ipykernel==6.8.0\n",
            "  Downloading ipykernel-6.8.0-py3-none-any.whl (128 kB)\n",
            "Collecting ipython==8.0.1\n",
            "  Downloading ipython-8.0.1-py3-none-any.whl (747 kB)\n",
            "Collecting ipython-genutils==0.2.0\n",
            "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting ipywidgets==7.6.5\n",
            "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
            "Collecting iso-639==0.4.5\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "Collecting jaraco-classes==3.2.1\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting jaraco-collections==3.5.1\n",
            "  Downloading jaraco.collections-3.5.1-py3-none-any.whl (10 kB)\n",
            "Collecting jaraco-context==4.1.1\n",
            "  Downloading jaraco.context-4.1.1-py3-none-any.whl (4.4 kB)\n",
            "Collecting jaraco-functools==3.5.0\n",
            "  Downloading jaraco.functools-3.5.0-py3-none-any.whl (7.0 kB)\n",
            "Collecting jaraco-text==3.7.0\n",
            "  Downloading jaraco.text-3.7.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting jedi==0.18.1\n",
            "  Using cached jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Collecting jinja2==3.0.3\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
            "Collecting jmespath==0.10.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting joblib==1.1.0\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Collecting jsonnet==0.18.0\n",
            "  Using cached jsonnet-0.18.0.tar.gz (592 kB)\n",
            "Collecting jsonschema==4.4.0\n",
            "  Downloading jsonschema-4.4.0-py3-none-any.whl (72 kB)\n",
            "Collecting jupyter==1.0.0\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting jupyter-client==7.1.2\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "Collecting jupyter-console==6.4.0\n",
            "  Downloading jupyter_console-6.4.0-py3-none-any.whl (22 kB)\n",
            "Collecting jupyter-core==4.9.1\n",
            "  Downloading jupyter_core-4.9.1-py3-none-any.whl (86 kB)\n",
            "Collecting jupyterlab-pygments==0.1.2\n",
            "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
            "Collecting jupyterlab-widgets==1.0.2\n",
            "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
            "Collecting langcodes==3.3.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "Collecting lmdb==1.3.0\n",
            "  Downloading lmdb-1.3.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (305 kB)\n",
            "Collecting lxml==4.7.1\n",
            "  Downloading lxml-4.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
            "Collecting markupsafe==2.0.1\n",
            "  Downloading MarkupSafe-2.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
            "Collecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Collecting matplotlib-inline==0.1.3\n",
            "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
            "Collecting mistune==0.8.4\n",
            "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting more-itertools==8.12.0\n",
            "  Downloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n",
            "Collecting multidict==6.0.2\n",
            "  Downloading multidict-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "Collecting multiprocess==0.70.12.2\n",
            "  Downloading multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
            "Collecting munch==2.5.0\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting murmurhash==1.0.6\n",
            "  Downloading murmurhash-1.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Collecting mypy-extensions==0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting nbclient==0.5.10\n",
            "  Downloading nbclient-0.5.10-py3-none-any.whl (69 kB)\n",
            "Collecting nbconvert==6.4.1\n",
            "  Downloading nbconvert-6.4.1-py3-none-any.whl (557 kB)\n",
            "Collecting nbformat==5.1.3\n",
            "  Downloading nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
            "Collecting nest-asyncio==1.5.4\n",
            "  Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB)\n",
            "Collecting nltk==3.6.5\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "Collecting notebook==6.4.8\n",
            "  Downloading notebook-6.4.8-py3-none-any.whl (9.9 MB)\n",
            "Collecting numpy==1.22.1\n",
            "  Downloading numpy-1.22.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "Collecting omegaconf==2.1.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "Collecting packaging==21.3\n",
            "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
            "Collecting pandas==1.4.0\n",
            "  Downloading pandas-1.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "Collecting pandocfilters==1.5.0\n",
            "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting parso==0.8.3\n",
            "  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "Collecting pathspec==0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pathtools==0.1.2\n",
            "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting pathy==0.6.1\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "Collecting patternfork-nosql==3.6\n",
            "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
            "Collecting pdfminer-six==20211012\n",
            "  Downloading pdfminer.six-20211012-py3-none-any.whl (5.6 MB)\n",
            "Collecting pexpect==4.8.0\n",
            "  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "Collecting pickleshare==0.7.5\n",
            "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pillow==9.0.0\n",
            "  Downloading Pillow-9.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Collecting platformdirs==2.4.1\n",
            "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
            "Collecting pluggy==1.0.0\n",
            "  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting portend==3.1.0\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting preshed==3.0.6\n",
            "  Downloading preshed-3.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
            "Collecting prometheus-client==0.13.1\n",
            "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "Collecting promise==2.3\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Collecting prompt-toolkit==3.0.26\n",
            "  Downloading prompt_toolkit-3.0.26-py3-none-any.whl (375 kB)\n",
            "Collecting protobuf==3.19.4\n",
            "  Downloading protobuf-3.19.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting psutil==5.9.0\n",
            "  Downloading psutil-5.9.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "Collecting ptyprocess==0.7.0\n",
            "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting pure-eval==0.2.2\n",
            "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting py==1.11.0\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "Collecting pyarrow==6.0.1\n",
            "  Downloading pyarrow-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
            "Collecting pyasn1==0.4.8\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting pyasn1-modules==0.2.8\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting pycparser==2.21\n",
            "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "Collecting pydantic==1.8.2\n",
            "  Downloading pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
            "Collecting pygments==2.11.2\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "Collecting pyparsing==3.0.7\n",
            "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
            "Collecting pyrsistent==0.18.1\n",
            "  Using cached pyrsistent-0.18.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\n",
            "Collecting pytest==6.2.5\n",
            "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
            "Collecting python-dateutil==2.8.2\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting python-docx==0.8.11\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "Collecting python-dotenv==0.19.2\n",
            "  Using cached python_dotenv-0.19.2-py2.py3-none-any.whl (17 kB)\n",
            "Collecting pytz==2021.3\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "Collecting pyyaml==6.0\n",
            "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
            "Collecting pyzmq==22.3.0\n",
            "  Downloading pyzmq-22.3.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Collecting qtconsole==5.2.2\n",
            "  Downloading qtconsole-5.2.2-py3-none-any.whl (120 kB)\n",
            "Collecting qtpy==2.0.1\n",
            "  Downloading QtPy-2.0.1-py3-none-any.whl (65 kB)\n",
            "Collecting regex==2022.1.18\n",
            "  Downloading regex-2022.1.18-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
            "Collecting requests==2.27.1\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Collecting rsa==4.8\n",
            "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting s3transfer==0.5.1\n",
            "  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
            "Collecting sacremoses==0.0.47\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "Collecting scikit-learn==1.0.2\n",
            "  Downloading scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
            "Collecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)\n",
            "Collecting send2trash==1.8.0\n",
            "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
            "Collecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting sentry-sdk==1.5.4\n",
            "  Downloading sentry_sdk-1.5.4-py2.py3-none-any.whl (143 kB)\n",
            "Collecting sgmllib3k==1.0.0\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting shortuuid==1.0.8\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting six==1.16.0\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting sklearn==0.0\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Collecting smart-open==5.2.1\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "Collecting smmap==5.0.0\n",
            "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting soupsieve==2.3.1\n",
            "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
            "Collecting spacy==3.2.1\n",
            "  Downloading spacy-3.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\n",
            "Collecting spacy-legacy==3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Collecting spacy-loggers==1.0.1\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting srsly==2.4.2\n",
            "  Downloading srsly-2.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "Collecting stack-data==0.1.4\n",
            "  Downloading stack_data-0.1.4-py3-none-any.whl (20 kB)\n",
            "Collecting tempora==5.0.1\n",
            "  Downloading tempora-5.0.1-py3-none-any.whl (15 kB)\n",
            "Collecting tensorboardx==2.4.1\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "Collecting termcolor==1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting terminado==0.13.1\n",
            "  Downloading terminado-0.13.1-py3-none-any.whl (14 kB)\n",
            "Collecting testpath==0.5.0\n",
            "  Downloading testpath-0.5.0-py3-none-any.whl (84 kB)\n",
            "Collecting thinc==8.0.13\n",
            "  Downloading thinc-8.0.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (635 kB)\n",
            "Collecting threadpoolctl==3.1.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting tokenizers==0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Collecting toml==0.10.2\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tomli==2.0.0\n",
            "  Downloading tomli-2.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting torchvision==0.11.3\n",
            "  Downloading torchvision-0.11.3-cp39-cp39-manylinux1_x86_64.whl (23.2 MB)\n",
            "Collecting tornado==6.1\n",
            "  Downloading tornado-6.1-cp39-cp39-manylinux2010_x86_64.whl (427 kB)\n",
            "Collecting tqdm==4.62.3\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Collecting traitlets==5.1.1\n",
            "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\n",
            "Collecting transformers==4.15.0\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "Collecting typer==0.4.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting urllib3==1.26.8\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "Collecting wandb==0.12.10\n",
            "  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n",
            "Collecting wasabi==0.9.0\n",
            "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
            "Collecting wcwidth==0.2.5\n",
            "  Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting webencodings==0.5.1\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting widgetsnbextension==3.5.2\n",
            "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Collecting xxhash==2.0.2\n",
            "  Downloading xxhash-2.0.2-cp39-cp39-manylinux2010_x86_64.whl (243 kB)\n",
            "Collecting yarl==1.7.2\n",
            "  Downloading yarl-1.7.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (304 kB)\n",
            "Collecting yaspin==2.1.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting zc-lockfile==2.0\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: torch<1.11.0,>=1.6.0 in /usr/local/envs/rome/lib/python3.9/site-packages (from allennlp==2.9.0->-r /content/rome/scripts/condaenv.oy889v8l.requirements.txt (line 3)) (1.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/envs/rome/lib/python3.9/site-packages (from black==22.1.0->-r /content/rome/scripts/condaenv.oy889v8l.requirements.txt (line 14)) (4.3.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/envs/rome/lib/python3.9/site-packages (from ipython==8.0.1->-r /content/rome/scripts/condaenv.oy889v8l.requirements.txt (line 62)) (63.4.1)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/rome/lib/python3.9/site-packages (from requests==2.27.1->-r /content/rome/scripts/condaenv.oy889v8l.requirements.txt (line 146)) (2022.6.15)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "  Downloading fsspec-2022.7.0-py3-none-any.whl (141 kB)\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, checklist, fairscale, future, iso-639, jsonnet, pathtools, patternfork-nosql, promise, python-docx, sgmllib3k, sklearn, termcolor\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=b9ca3241c1e95ad34b4e9cd47f310457aa5adf2bc9d953c14f9bea1cb29b486a\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/3c/ae/14db087e6018de74810afe32eb6ac890ef9c68ba19b00db97a\n",
            "  Building wheel for checklist (setup.py): started\n",
            "  Building wheel for checklist (setup.py): finished with status 'done'\n",
            "  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165618 sha256=fbffab72a1e1d7246991e2a7e509a7439299541f407a035a3a23cce9c341a5d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/48/f4/983e6cfe66fed9979451c546178d6d6f92ba1d6dc5e6add3e4\n",
            "  Building wheel for fairscale (PEP 517): started\n",
            "  Building wheel for fairscale (PEP 517): finished with status 'done'\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.5-py3-none-any.whl size=297965 sha256=86cc1630fd0f41ea64fd2fcba3d3c932d2a903c3c091a9d70f211598b3e2fe33\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/60/4d/76f20153ab26fa3846ee9f7a9fe9e90194bdefc95ea79df1e8\n",
            "  Building wheel for future (setup.py): started\n",
            "  Building wheel for future (setup.py): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=919d9a453c174ddffe8d3e743544c6b5b7a4ba058c639b4d7f6aed1fff5fa945\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/a0/d3/4030d9f80e6b3be787f19fc911b8e7aa462986a40ab1e4bb94\n",
            "  Building wheel for iso-639 (setup.py): started\n",
            "  Building wheel for iso-639 (setup.py): finished with status 'done'\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=168841 sha256=db0019c2e2d3dd4d32cda3e5c2be001ee482fd2c288d000b2d2a55facd42231a\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/3f/de/07f35ac2a2cd11ff30224e3fc6fbf458d7fc95effb1f673431\n",
            "  Building wheel for jsonnet (setup.py): started\n",
            "  Building wheel for jsonnet (setup.py): finished with status 'done'\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp39-cp39-linux_x86_64.whl size=3982496 sha256=7d2135628bea7c9e4398901030555fdfd7c3b956d2c635a483e144091906f3e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/df/6e/1554c30d27445bdb4c63c472e4c0c34f732820d37aa414495b\n",
            "  Building wheel for pathtools (setup.py): started\n",
            "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=d67dbfb29a5a58eaa369ff1b6af77b5c72f7918f79ebb125c7c6a998af65c83a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "  Building wheel for patternfork-nosql (setup.py): started\n",
            "  Building wheel for patternfork-nosql (setup.py): finished with status 'done'\n",
            "  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332783 sha256=a61217b753d77542cd81801211cd8484bf67160c6300dcb1f90f0fbeb67b5db5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/f8/c1/165dbb1ce03c55f2a5c7e075ef9c1c6ff71b3620fb4dbcda38\n",
            "  Building wheel for promise (setup.py): started\n",
            "  Building wheel for promise (setup.py): finished with status 'done'\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=00abd7b1fbe25e910fafab04e4d7c4ccb34500e3e0bfee00541d23925a78b25b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
            "  Building wheel for python-docx (setup.py): started\n",
            "  Building wheel for python-docx (setup.py): finished with status 'done'\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184489 sha256=bdb5ebdbec2d5a9ccf78fff6c0d56c5620dbc75a327d9f20a144f26655d28491\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/8b/7c/09ae60c42c7ba4ed2dddaf2b8b9186cb105255856d6ed3dba5\n",
            "  Building wheel for sgmllib3k (setup.py): started\n",
            "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=cd63760b554b3efdf2b80021bc1ad7a44787c1e1793a949c6520287aa7380c6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/7a/a7/78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
            "  Building wheel for sklearn (setup.py): started\n",
            "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1304 sha256=ad7307a814fc2c369ae1ef945dcf2e6c45c73c403d9baccb0803aba4c414fd59\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/7b/98/b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=01a71ba33a271cd6a2c5da7b926f2ce6962d023de43a29357108bbd93c139af8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
            "Successfully built antlr4-python3-runtime checklist fairscale future iso-639 jsonnet pathtools patternfork-nosql promise python-docx sgmllib3k sklearn termcolor\n",
            "Installing collected packages: traitlets, six, pyrsistent, attrs, wcwidth, tornado, tomli, pyzmq, python-dateutil, pyparsing, pycparser, pure-eval, ptyprocess, platformdirs, pathspec, parso, nest-asyncio, mypy-extensions, jupyter-core, jsonschema, ipython-genutils, executing, entrypoints, click, asttokens, webencodings, stack-data, pygments, prompt-toolkit, pickleshare, pexpect, packaging, nbformat, matplotlib-inline, markupsafe, jupyter-client, jedi, decorator, cffi, black, backcall, testpath, pyasn1, pandocfilters, nbclient, more-itertools, mistune, jupyterlab-pygments, jinja2, ipython, defusedxml, debugpy, bleach, argon2-cffi-bindings, urllib3, terminado, send2trash, rsa, pytz, pyasn1-modules, protobuf, prometheus-client, nbconvert, jaraco-functools, jaraco-context, ipykernel, idna, charset-normalizer, cachetools, argon2-cffi, tempora, requests, numpy, notebook, murmurhash, jmespath, jaraco-text, jaraco-classes, googleapis-common-protos, google-auth, cymem, catalogue, zc-lockfile, widgetsnbextension, wasabi, typer, tqdm, srsly, soupsieve, smmap, smart-open, sgmllib3k, regex, qtpy, pyyaml, pydantic, preshed, portend, multidict, lxml, jupyterlab-widgets, joblib, jaraco-collections, google-crc32c, google-api-core, frozenlist, filelock, cryptography, cheroot, chardet, botocore, blis, yarl, tokenizers, thinc, termcolor, spacy-loggers, spacy-legacy, scipy, sacremoses, s3transfer, qtconsole, python-docx, pdfminer-six, pathy, nltk, langcodes, jupyter-console, ipywidgets, huggingface-hub, google-resumable-media, google-cloud-core, gitdb, future, feedparser, cherrypy, beautifulsoup4, backports-csv, async-timeout, aiosignal, yaspin, transformers, toml, threadpoolctl, spacy, shortuuid, sentry-sdk, py, psutil, promise, pluggy, pillow, patternfork-nosql, pathtools, munch, jupyter, iso-639, iniconfig, google-cloud-storage, gitpython, fsspec, docker-pycreds, dill, boto3, antlr4-python3-runtime, aiohttp, xxhash, wandb, torchvision, tensorboardx, sentencepiece, scikit-learn, pytest, pyarrow, pandas, omegaconf, multiprocess, lmdb, kiwisolver, jsonnet, h5py, fonttools, fairscale, cycler, checklist, cached-path, base58, sklearn, python-dotenv, matplotlib, hydra-core, higher, einops, datasets, allennlp\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 allennlp-2.9.0 antlr4-python3-runtime-4.8 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 asttokens-2.0.8 async-timeout-4.0.2 attrs-22.1.0 backcall-0.2.0 backports-csv-1.0.7 base58-2.1.1 beautifulsoup4-4.11.1 black-22.1.0 bleach-5.0.1 blis-0.7.5 boto3-1.20.47 botocore-1.23.47 cached-path-1.0.2 cachetools-5.0.0 catalogue-2.0.6 cffi-1.15.1 chardet-4.0.0 charset-normalizer-2.0.11 checklist-0.0.11 cheroot-8.6.0 cherrypy-18.6.1 click-8.0.3 cryptography-36.0.1 cycler-0.11.0 cymem-2.0.6 datasets-1.18.3 debugpy-1.6.3 decorator-5.1.1 defusedxml-0.7.1 dill-0.3.4 docker-pycreds-0.4.0 einops-0.4.0 entrypoints-0.4 executing-1.0.0 fairscale-0.4.5 feedparser-6.0.8 filelock-3.4.2 fonttools-4.37.1 frozenlist-1.3.0 fsspec-2022.1.0 future-0.18.2 gitdb-4.0.9 gitpython-3.1.26 google-api-core-2.5.0 google-auth-2.6.0 google-cloud-core-2.2.2 google-cloud-storage-1.44.0 google-crc32c-1.3.0 google-resumable-media-2.1.0 googleapis-common-protos-1.54.0 h5py-3.6.0 higher-0.2.1 huggingface-hub-0.2.1 hydra-core-1.1.1 idna-3.3 iniconfig-1.1.1 ipykernel-6.15.2 ipython-8.5.0 ipython-genutils-0.2.0 ipywidgets-8.0.2 iso-639-0.4.5 jaraco-classes-3.2.1 jaraco-collections-3.5.1 jaraco-context-4.1.1 jaraco-functools-3.5.0 jaraco-text-3.7.0 jedi-0.18.1 jinja2-3.1.2 jmespath-0.10.0 joblib-1.1.0 jsonnet-0.18.0 jsonschema-4.16.0 jupyter-1.0.0 jupyter-client-7.3.5 jupyter-console-6.4.4 jupyter-core-4.11.1 jupyterlab-pygments-0.2.2 jupyterlab-widgets-3.0.3 kiwisolver-1.4.4 langcodes-3.3.0 lmdb-1.3.0 lxml-4.9.1 markupsafe-2.1.1 matplotlib-3.5.1 matplotlib-inline-0.1.6 mistune-2.0.4 more-itertools-8.12.0 multidict-6.0.2 multiprocess-0.70.12.2 munch-2.5.0 murmurhash-1.0.6 mypy-extensions-0.4.3 nbclient-0.6.8 nbconvert-7.0.0 nbformat-5.4.0 nest-asyncio-1.5.5 nltk-3.6.5 notebook-6.4.12 numpy-1.22.1 omegaconf-2.1.1 packaging-21.3 pandas-1.4.0 pandocfilters-1.5.0 parso-0.8.3 pathspec-0.9.0 pathtools-0.1.2 pathy-0.6.1 patternfork-nosql-3.6 pdfminer-six-20211012 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.0.0 platformdirs-2.4.1 pluggy-1.0.0 portend-3.1.0 preshed-3.0.6 prometheus-client-0.14.1 promise-2.3 prompt-toolkit-3.0.31 protobuf-3.19.4 psutil-5.9.2 ptyprocess-0.7.0 pure-eval-0.2.2 py-1.11.0 pyarrow-6.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pydantic-1.8.2 pygments-2.13.0 pyparsing-3.0.9 pyrsistent-0.18.1 pytest-6.2.5 python-dateutil-2.8.2 python-docx-0.8.11 python-dotenv-0.19.2 pytz-2021.3 pyyaml-6.0 pyzmq-23.2.1 qtconsole-5.3.2 qtpy-2.2.0 regex-2022.1.18 requests-2.27.1 rsa-4.8 s3transfer-0.5.1 sacremoses-0.0.47 scikit-learn-1.0.2 scipy-1.7.3 send2trash-1.8.0 sentencepiece-0.1.96 sentry-sdk-1.5.4 sgmllib3k-1.0.0 shortuuid-1.0.8 six-1.16.0 sklearn-0.0 smart-open-5.2.1 smmap-5.0.0 soupsieve-2.3.2.post1 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 stack-data-0.5.0 tempora-5.0.1 tensorboardx-2.4.1 termcolor-1.1.0 terminado-0.15.0 testpath-0.5.0 thinc-8.0.13 threadpoolctl-3.1.0 tokenizers-0.10.3 toml-0.10.2 tomli-2.0.0 torchvision-0.11.3 tornado-6.2 tqdm-4.62.3 traitlets-5.3.0 transformers-4.15.0 typer-0.4.0 urllib3-1.26.8 wandb-0.12.10 wasabi-0.9.0 wcwidth-0.2.5 webencodings-0.5.1 widgetsnbextension-4.0.3 xxhash-2.0.2 yarl-1.7.2 yaspin-2.1.0 zc-lockfile-2.0\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate rome\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda init\n",
        "!conda activate rome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIfbBQvAJj1b",
        "outputId": "58467a7b-18ef-4e90-ca46-d29280cf772e"
      },
      "id": "nIfbBQvAJj1b",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.7/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n",
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python -m experiments.evaluate \\\n",
        "    --alg_name=ROME \\\n",
        "    --model_name=gpt2-xl \\\n",
        "    --hparams_fname=gpt2-xl.json \\\n",
        "    --dataset_size_limit 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "qlgnAsWSyVg-",
        "outputId": "573b4d7c-79b6-496d-f13c-94536eecef3b"
      },
      "id": "qlgnAsWSyVg-",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/local/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/rome/experiments/evaluate.py\", line 4, in <module>\n",
            "    import torch\n",
            "ModuleNotFoundError: No module named 'torch'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ac820fe4806a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python -m experiments.evaluate \\\\\\n    --alg_name=ROME \\\\\\n    --model_name=gpt2-xl \\\\\\n    --hparams_fname=gpt2-xl.json \\\\\\n    --dataset_size_limit 100\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'python -m experiments.evaluate \\\\\\n    --alg_name=ROME \\\\\\n    --model_name=gpt2-xl \\\\\\n    --hparams_fname=gpt2-xl.json \\\\\\n    --dataset_size_limit 100\\n'' returned non-zero exit status 1."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19da731918ee441e95c75190086b0c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08c74ea5219f416ca242dea8d641b389",
              "IPY_MODEL_4155116ffa0d4a709ce11f95fcee0d09",
              "IPY_MODEL_9a76f0bcdba5451d9080bcf9c0929ec6"
            ],
            "layout": "IPY_MODEL_9be27f7ce94e4ad18b2190721dd7ccc0"
          }
        },
        "08c74ea5219f416ca242dea8d641b389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f0b0a1f4c44035af4808bfe94bafa9",
            "placeholder": "​",
            "style": "IPY_MODEL_467edab547d34d918b5d5cddd0525102",
            "value": "100%"
          }
        },
        "4155116ffa0d4a709ce11f95fcee0d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e70f416baee43c4afe26fb92e24dce1",
            "max": 163841186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d482be2e1fd4e3d975f7d5c738bc6fd",
            "value": 163841186
          }
        },
        "9a76f0bcdba5451d9080bcf9c0929ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33ab9c089dc464286620c6410360fb8",
            "placeholder": "​",
            "style": "IPY_MODEL_43b30a6a01804c29b2ae729e9eee17c1",
            "value": " 156M/156M [00:02&lt;00:00, 74.1MB/s]"
          }
        },
        "9be27f7ce94e4ad18b2190721dd7ccc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59f0b0a1f4c44035af4808bfe94bafa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "467edab547d34d918b5d5cddd0525102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e70f416baee43c4afe26fb92e24dce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d482be2e1fd4e3d975f7d5c738bc6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e33ab9c089dc464286620c6410360fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b30a6a01804c29b2ae729e9eee17c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2ceb91574e045aa9bd6bff17cb9e267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_773410b867df4a06b6b9de497061ebd2",
              "IPY_MODEL_adb632b2120c414d9e91417bdae3eedb",
              "IPY_MODEL_bf54a644d30f45c2badf63cc4b7c6ce0"
            ],
            "layout": "IPY_MODEL_dfa503bed0ce4cac8efb1b0a62f5c95a"
          }
        },
        "773410b867df4a06b6b9de497061ebd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d776c17f6a414230a6b1a859ea774291",
            "placeholder": "​",
            "style": "IPY_MODEL_3979b25f421b410ebbebd191eb93652b",
            "value": "  0%"
          }
        },
        "adb632b2120c414d9e91417bdae3eedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbd1e846ec84ac392e57bc0b818f005",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3ed84760135416997b5e5354a251fb3",
            "value": 0
          }
        },
        "bf54a644d30f45c2badf63cc4b7c6ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ccf8cfd3a014bd28f2da7359d8eb963",
            "placeholder": "​",
            "style": "IPY_MODEL_2e4a41ca22144ec2a840ccd70e32ec42",
            "value": " 0/1000 [00:00&lt;?, ?it/s]"
          }
        },
        "dfa503bed0ce4cac8efb1b0a62f5c95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d776c17f6a414230a6b1a859ea774291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3979b25f421b410ebbebd191eb93652b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adbd1e846ec84ac392e57bc0b818f005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ed84760135416997b5e5354a251fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ccf8cfd3a014bd28f2da7359d8eb963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4a41ca22144ec2a840ccd70e32ec42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}